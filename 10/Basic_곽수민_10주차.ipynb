{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62df373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 텐서플로 ≥2.0 필수\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10401c",
   "metadata": {},
   "source": [
    "## 10.1.3 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a25a1",
   "metadata": {},
   "source": [
    "TLU(Threshold Logic Unit) or LTU(Linear Threshold Unit)이라고 불리는 조금 다른 형태의 인공 뉴런을 기반으로 함(입력과 출력이 이진값이 아닌 어떤 숫자이고, 각각의 입력 연결은 가중치와 연결되어 있음) TLU는 입력의 가중치 합을 계산($z = w_1x_1 + w_2x_2 + ... + w_nx_n = x^Tw$)한 뒤 계산된 합에 계단함수를 적용하여 결과를 출력.\n",
    "\n",
    "$h_w(x) = step(z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d016ce92",
   "metadata": {},
   "source": [
    "퍼셉트론에서 가장 널리 쓰이는 계단 함수는 헤비사이드 계단함수( z<0일때 0, z$\\ge$0일때 1, 부호함수 대신에 사용하기도 함)\n",
    "\n",
    "하나의 TLU는 간단한 선형 이진 분류문제에 활용할 수 있음. 입력의 선형 조합을 계산해 그 값이 임계값을 넘으면 양성클래스, 아니면 음성클래스를 출력한다.\n",
    "\n",
    "퍼셉트론은 층이 하나뿐인 TLU로 구성. 한 층에 있는 모든 뉴런이 이전 층의 모든 뉴런과 연결되어 있을 때 이를 완전 연결층(or 밀집 층)이라고 부르며, 퍼셉트론의 입력은 입력뉴런이라 불리는 특별한 통과 뉴런(입력값 그대로 출력)에 주입."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb26d03",
   "metadata": {},
   "source": [
    "(완전 연결 층의 출력 계산) $h_{W, b}(X) = \\phi (XW + b)$\n",
    "- X : 입력 특성의 행렬\n",
    "- W : 가중치 행렬\n",
    "- b : 편향 벡터\n",
    "- $\\phi$ : 활성화함수. 인공뉴런이 TLU일 경우 이 함수는 계단함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b7ea33",
   "metadata": {},
   "source": [
    "퍼셉트론은 헤브의 규칙(두 뉴런이 동시에 활성화될 때 마다 이들 사이의 연결 가중치가 증가하는 경향)을 기반으로 하나 네트워크가 예측할 때 만드는 오차를 반영하도록 약간 변형하여 학습\n",
    "$w_{i, j}^{(next step)} = w_{i, j} + \\eta (y_j - \\hat{y_j})x_j $\n",
    "- $w_{i, j}$ : i번째 입력 뉴런과 j번째 출력 뉴런 사이를 연결하는 가중치\n",
    "- $x_i$ : 현재 훈련 샘플의 i번째 뉴런의 입력값\n",
    "- $\\hat{y_j}$ : 현재 훈련 샘플의 j번째 출력 뉴런의 출력값\n",
    "- $y_j$ : 현재 훈련 샘플의 j번째 출력 뉴런의 타깃값\n",
    "- $\\eta$ : 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d477834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytnal\\AppData\\Local\\Temp\\ipykernel_4816\\395347572.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = (iris.target==0).astype(np.int)      # 부채붓꽃(Setosa)이면 1, 아니면 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]     # 꽃잎 길이와 너비만 활용\n",
    "y = (iris.target==0).astype(np.int)      # 부채붓꽃(Setosa)이면 1, 아니면 0\n",
    "\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c32c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f48bf9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장: perceptron_iris_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "save_fig(\"perceptron_iris_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790c1bcb",
   "metadata": {},
   "source": [
    "퍼셉트론은 XOR 분류문제 등 일부 간단한 문제를 풀 수 없는 약점 존재. \n",
    "\n",
    "퍼셉트론을 여러 개 쌓아올리면 일부 제약이 줄어듬 -> 다중 퍼셉트론(MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4fcbb3",
   "metadata": {},
   "source": [
    "## 10.1.4 다중 퍼셉트론과 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9e8850",
   "metadata": {},
   "source": [
    "다중 퍼셉트론은 입력층(input layer) 하나와 은닉층(hidden layer)라 불리는 하나 이상의 TLU 층과 마지막 출력층(output layer)로 구성. 출력층을 제외하고 모든 층은 편향 뉴런을 포함하여 다음 층과 완전히 연결됨.\n",
    "\n",
    "(신호는 입력->출력 한 방향으로만 흐르므로, 이 구조를 feed-forward 신경망, FNN이라 부름)\n",
    "\n",
    "- DNN(심층 신경망) : 은닉층을 여러 개 쌓아 올린 인공 신경망\n",
    "\n",
    "다중 퍼셉트론을 훈련하는 방법 -> 역전파(네트워크를 정방향, 역방향 한번씩 통과하는 것 만으로도 모든 모델 파라미터에 대한 네트워크 오차의 그라디언트를 계산하는 알고리즘)\n",
    "\n",
    "- ex) 32개의 샘플이 포함된 하나의 미니배치씩 전체 훈련 세트를 처리하는데, 이 과정을 여러번 반복한다. 이 반복을 에포크라 칭한다.\n",
    "- 각 미니배치는 네트워크의 input layer으로 전달되어 첫번째 hidden layer로 전달된다. 그 다음 해당층에 있는 모든 뉴런의 출력을 계산하고, 다음 층으로 전달된다(정방향 계산). 이러한 계산은 output layer로 전달되어 출력을 계산할 때까지 지속된다.\n",
    "- 알고리즘이 네트워크의 출력 오차를 측정한다.\n",
    "- 각 출력 연결이 오차에 기여하는 정도를 계산한다.(chain rule을 통해 바르게 수행)\n",
    "- 또 다시 chain rule을 적용하여 이전 층의 웨이트가 이 오차의 기여 정도에 얼마나 기여했는지 측정. 이렇게 input layer에 도달할 때까지 역방향으로 계속된다.\n",
    "- 마지막으로 알고리즘은 Gradient Descent를 통해 방금 계산한 오차 그라디언트를 업데이트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29083d4f",
   "metadata": {},
   "source": [
    "이 알고리즘이 잘 작동하고자 계단함수에 여러 활성화 함수를 정의.\n",
    "- Sigmoid(Logistic) Function : $\\sigma(z) ={1 \\over{1 + exp(-z)}}$\n",
    "- 쌍곡 탄젠트 함수 : $tanh(z) = 2 \\sigma (2z)$\n",
    "- ReLU : ReLu(z) = max(0, z)    -> 연속적이지만 z=0에서 미분가능하지 않으며, z<0일 경우 기울기는 0이다. 하지만 실제로는 잘 작동하며 계산속도가 빠르다는 장점 덕분에 기본 Activation Function이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "269325b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ee8177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장: activation_functions_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=1, label=\"Step\")\n",
    "plt.plot(z, sigmoid(z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=1, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(sigmoid, z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "#plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Derivatives\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"activation_functions_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd10417",
   "metadata": {},
   "source": [
    "## 10.2.2 시퀀셜 API를 이용하여 이미지 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f4ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656f5f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 8s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c7d9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d01bc5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b1d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19314c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bfd10b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련셋의 첫번째 데이터는 코트\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4c41d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='binary')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb52e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장: fashion_mnist_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d63501",
   "metadata": {},
   "source": [
    "- 첫번째 라인 : 케라스의 가장 간단한 신경망 모델인 Sequential 모델을 생성\n",
    "- Flatten 층은 입력 이미지를 1D 배열로 변환. 즉 X.reshape(-1, 28*28)을 계산\n",
    "- Dense 층은 각자 가중치 행렬을 관리\n",
    "- 분류 문제이고, 분류 클래스가 10개이므로 10개의 뉴런을 가진 softmax 함수로 마지막을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b2d1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01d28195",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "694869a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서처럼 하나하나 add 안해주고 한번에 만들 수도 있음\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5383a3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x1b9540ac4f0>,\n",
       " <keras.layers.core.dense.Dense at 0x1b9540aceb0>,\n",
       " <keras.layers.core.dense.Dense at 0x1b9540ace80>,\n",
       " <keras.layers.core.dense.Dense at 0x1b9540acf40>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2ff959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b2de5e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# 위의 뉴런층 시각화... 인데 망할놈의 graphviz\n",
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc7afce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85fecac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7ed3b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
       "         0.03859074, -0.06889391],\n",
       "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
       "        -0.02763776, -0.04165364],\n",
       "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
       "         0.07121518, -0.07331658],\n",
       "       ...,\n",
       "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
       "         0.00228987,  0.05581069],\n",
       "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
       "         0.00034875,  0.02878492],\n",
       "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
       "         0.00272203, -0.06793761]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e7240c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aa17d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "371d2ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc3016cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "# 레이블이 정수 하나이고, 배타적이므로 sparse_categorical_crossentropy를 사용,\n",
    "# 만약 샘플마다 클래스별 확률을 가진다면 categorical_crossentropy를 사용해야 함\n",
    "# 만약 이진분류나 다중레이블 이진분류라면 출력층에 softmax 대신 sigmoid를 쓰고 binary_crossentropy 손실을 사용\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b07d83fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 2ms/step - loss: 0.7237 - accuracy: 0.7644 - val_loss: 0.5207 - val_accuracy: 0.8234\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4843 - accuracy: 0.8318 - val_loss: 0.4349 - val_accuracy: 0.8528\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4392 - accuracy: 0.8455 - val_loss: 0.5337 - val_accuracy: 0.7984\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4125 - accuracy: 0.8564 - val_loss: 0.3921 - val_accuracy: 0.8646\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3939 - accuracy: 0.8618 - val_loss: 0.3750 - val_accuracy: 0.8682\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3753 - accuracy: 0.8675 - val_loss: 0.3703 - val_accuracy: 0.8730\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3632 - accuracy: 0.8716 - val_loss: 0.3619 - val_accuracy: 0.8710\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3519 - accuracy: 0.8747 - val_loss: 0.3842 - val_accuracy: 0.8612\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3416 - accuracy: 0.8787 - val_loss: 0.3584 - val_accuracy: 0.8710\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3321 - accuracy: 0.8822 - val_loss: 0.3426 - val_accuracy: 0.8780\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3242 - accuracy: 0.8838 - val_loss: 0.3439 - val_accuracy: 0.8780\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3150 - accuracy: 0.8865 - val_loss: 0.3311 - val_accuracy: 0.8834\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3082 - accuracy: 0.8890 - val_loss: 0.3264 - val_accuracy: 0.8874\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3021 - accuracy: 0.8918 - val_loss: 0.3411 - val_accuracy: 0.8786\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2948 - accuracy: 0.8936 - val_loss: 0.3215 - val_accuracy: 0.8856\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2892 - accuracy: 0.8969 - val_loss: 0.3096 - val_accuracy: 0.8900\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2840 - accuracy: 0.8974 - val_loss: 0.3573 - val_accuracy: 0.8724\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2779 - accuracy: 0.8997 - val_loss: 0.3144 - val_accuracy: 0.8890\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2729 - accuracy: 0.9022 - val_loss: 0.3116 - val_accuracy: 0.8900\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2676 - accuracy: 0.9031 - val_loss: 0.3261 - val_accuracy: 0.8812\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2626 - accuracy: 0.9055 - val_loss: 0.3059 - val_accuracy: 0.8934\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2578 - accuracy: 0.9069 - val_loss: 0.2969 - val_accuracy: 0.8954\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2535 - accuracy: 0.9085 - val_loss: 0.2986 - val_accuracy: 0.8944\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2486 - accuracy: 0.9099 - val_loss: 0.3062 - val_accuracy: 0.8890\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2445 - accuracy: 0.9120 - val_loss: 0.2976 - val_accuracy: 0.8954\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2407 - accuracy: 0.9138 - val_loss: 0.3070 - val_accuracy: 0.8906\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2365 - accuracy: 0.9150 - val_loss: 0.3013 - val_accuracy: 0.8956\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2329 - accuracy: 0.9168 - val_loss: 0.3000 - val_accuracy: 0.8928\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2285 - accuracy: 0.9179 - val_loss: 0.3064 - val_accuracy: 0.8912\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2254 - accuracy: 0.9194 - val_loss: 0.3015 - val_accuracy: 0.8940\n"
     ]
    }
   ],
   "source": [
    "# 클래스별 비중이 편중되어있다면 fit() 인자 안에 class_weight로 적게 등장하는 클래스에 높은 가중치를 부여하면 됨\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79972847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf4fa2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "095cf1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df938b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a05c28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3353557586669922, 0.8837000131607056]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c367f8f",
   "metadata": {},
   "source": [
    "모델을 사용해 예측을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdbb9974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f344a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[9 2 1]\n",
      "['Ankle boot' 'Pullover' 'Trouser']\n"
     ]
    }
   ],
   "source": [
    "# 클래스 출력\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "print(y_pred)\n",
    "print(np.array(class_names)[y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caae28d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c903828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장: fashion_mnist_images_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_images_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9fbe9b",
   "metadata": {},
   "source": [
    "## 10.2.3 시퀀셜 API를 사용하여 회귀용 MLP 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2da590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)          # trian셋으로 fit을 했고, train 데이터에 fitting 되어있으므로 valid와 test는 fit을 안함\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f1d366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43f35071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8428 - val_loss: 0.8776\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5852 - val_loss: 0.4970\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4724 - val_loss: 0.4692\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4445 - val_loss: 0.4594\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4324 - val_loss: 0.4495\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.4425\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4161 - val_loss: 0.4318\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4082 - val_loss: 0.4311\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4018 - val_loss: 0.4230\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3981 - val_loss: 0.4195\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3931 - val_loss: 0.4166\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3895 - val_loss: 0.4135\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3855 - val_loss: 0.4155\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.4202\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3776 - val_loss: 0.4158\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3753 - val_loss: 0.3997\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4047\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3686 - val_loss: 0.3980\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3679 - val_loss: 0.3951\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3660 - val_loss: 0.3954\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)       # 하나의 값을 예측하므로 활성화함수가 없는 하나의 뉴런\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eaabdf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3768\n",
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.63506544],\n",
       "       [1.7379583 ],\n",
       "       [3.5857036 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a8e2814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85770156",
   "metadata": {},
   "source": [
    "## 10.2.4 함수형 API를 사용해 복잡한 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3cb736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fca234c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])       # 두번째 은닉층과 인풋층을 연결\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e466021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30)           930         ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7eb4c3f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3035 - val_loss: 0.7101\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6619 - val_loss: 0.6456\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6156 - val_loss: 0.6133\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5873 - val_loss: 0.5928\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5664 - val_loss: 0.5708\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5470 - val_loss: 0.5567\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5324 - val_loss: 0.5430\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5193 - val_loss: 0.5318\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5088 - val_loss: 0.5219\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4994 - val_loss: 0.5134\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4909 - val_loss: 0.5059\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4837 - val_loss: 0.4984\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4771 - val_loss: 0.4913\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4713 - val_loss: 0.4864\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4658 - val_loss: 0.4823\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4612 - val_loss: 0.4769\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4566 - val_loss: 0.4740\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4529 - val_loss: 0.4699\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4493 - val_loss: 0.4653\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4457 - val_loss: 0.4636\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4568\n",
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326180eb",
   "metadata": {},
   "source": [
    "일부 특성은 짧은 경로로 전달, 다른 특성은 깊은 경로로 전달하는 함수형 API\n",
    "\n",
    "(0 ~ 4), (2 ~ 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9965b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40f38091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytnal\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 1.7568 - val_loss: 0.8360\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7706 - val_loss: 0.7083\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6772 - val_loss: 0.6531\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6295 - val_loss: 0.6206\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5971 - val_loss: 0.5948\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5729 - val_loss: 0.5758\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5552 - val_loss: 0.5623\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5407 - val_loss: 0.5489\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5293 - val_loss: 0.5397\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5201 - val_loss: 0.5320\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5119 - val_loss: 0.5248\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5056 - val_loss: 0.5207\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5001 - val_loss: 0.5178\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4955 - val_loss: 0.5111\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4910 - val_loss: 0.5081\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4878 - val_loss: 0.5050\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4842 - val_loss: 0.5040\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4814 - val_loss: 0.5015\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4789 - val_loss: 0.4969\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4764 - val_loss: 0.4959\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4850\n",
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data = ((X_valid_A, X_valid_B), y_valid))\n",
    "\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af89456",
   "metadata": {},
   "source": [
    "규제를 위한 보조출력 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "963f56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7438c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6506b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력이 2개이므로 손실함수도 두개, 보조출력보다 주출력에 관심이 더 많으므로 가중치 조절\n",
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5bba1a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.9609 - main_output_loss: 0.8797 - aux_output_loss: 1.6922 - val_loss: 0.7013 - val_main_output_loss: 0.6408 - val_aux_output_loss: 1.2455\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6081 - main_output_loss: 0.5576 - aux_output_loss: 1.0629 - val_loss: 0.5657 - val_main_output_loss: 0.5206 - val_aux_output_loss: 0.9708\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5384 - main_output_loss: 0.4976 - aux_output_loss: 0.9050 - val_loss: 0.5294 - val_main_output_loss: 0.4957 - val_aux_output_loss: 0.8328\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5053 - main_output_loss: 0.4762 - aux_output_loss: 0.7672 - val_loss: 0.5135 - val_main_output_loss: 0.4868 - val_aux_output_loss: 0.7534\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4868 - main_output_loss: 0.4611 - aux_output_loss: 0.7186 - val_loss: 0.5042 - val_main_output_loss: 0.4818 - val_aux_output_loss: 0.7061\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4756 - main_output_loss: 0.4526 - aux_output_loss: 0.6835 - val_loss: 0.4890 - val_main_output_loss: 0.4674 - val_aux_output_loss: 0.6831\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4628 - main_output_loss: 0.4415 - aux_output_loss: 0.6551 - val_loss: 0.4754 - val_main_output_loss: 0.4545 - val_aux_output_loss: 0.6628\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4511 - main_output_loss: 0.4308 - aux_output_loss: 0.6342 - val_loss: 0.4710 - val_main_output_loss: 0.4507 - val_aux_output_loss: 0.6545\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4418 - main_output_loss: 0.4221 - aux_output_loss: 0.6182 - val_loss: 0.4564 - val_main_output_loss: 0.4357 - val_aux_output_loss: 0.6427\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4358 - main_output_loss: 0.4167 - aux_output_loss: 0.6080 - val_loss: 0.4531 - val_main_output_loss: 0.4340 - val_aux_output_loss: 0.6244\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4274 - main_output_loss: 0.4089 - aux_output_loss: 0.5936 - val_loss: 0.4454 - val_main_output_loss: 0.4273 - val_aux_output_loss: 0.6090\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4195 - main_output_loss: 0.4014 - aux_output_loss: 0.5825 - val_loss: 0.4385 - val_main_output_loss: 0.4210 - val_aux_output_loss: 0.5960\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4133 - main_output_loss: 0.3960 - aux_output_loss: 0.5688 - val_loss: 0.4398 - val_main_output_loss: 0.4220 - val_aux_output_loss: 0.6000\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4063 - main_output_loss: 0.3896 - aux_output_loss: 0.5569 - val_loss: 0.4555 - val_main_output_loss: 0.4416 - val_aux_output_loss: 0.5808\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3995 - main_output_loss: 0.3831 - aux_output_loss: 0.5471 - val_loss: 0.4364 - val_main_output_loss: 0.4208 - val_aux_output_loss: 0.5767\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3933 - main_output_loss: 0.3772 - aux_output_loss: 0.5381 - val_loss: 0.4146 - val_main_output_loss: 0.3985 - val_aux_output_loss: 0.5594\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3908 - main_output_loss: 0.3754 - aux_output_loss: 0.5300 - val_loss: 0.4122 - val_main_output_loss: 0.3967 - val_aux_output_loss: 0.5516\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3820 - main_output_loss: 0.3669 - aux_output_loss: 0.5181 - val_loss: 0.4056 - val_main_output_loss: 0.3898 - val_aux_output_loss: 0.5476\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3792 - main_output_loss: 0.3645 - aux_output_loss: 0.5119 - val_loss: 0.4018 - val_main_output_loss: 0.3867 - val_aux_output_loss: 0.5377\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3748 - main_output_loss: 0.3605 - aux_output_loss: 0.5041 - val_loss: 0.4021 - val_main_output_loss: 0.3880 - val_aux_output_loss: 0.5283\n"
     ]
    }
   ],
   "source": [
    "# 주출력과 보조출력이 같은 것을 예측하므로 둘다 y_train임\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, \n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "650b9408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3793 - main_output_loss: 0.3669 - aux_output_loss: 0.4912\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45d7853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B934888550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550d0efc",
   "metadata": {},
   "source": [
    "## 10.2.5 서브클래싱 API로 동적 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af4dd6d",
   "metadata": {},
   "source": [
    "시퀀셜 API와 함수형 API는 모두 선언적(사용할 층과 연결방식을 먼저 정의)이기 때문에 모델 저장, 복사, 공유, 구조출력, 디버깅 등에 좋지만 정적이기 때문에 단점 존재\n",
    "\n",
    "어떤 모델은 반복문을 포함하고 다양한 크기를 다루어야하며 조건문을 가지는 등 여러 동적 구조가 필요하다 -> 서브클래싱 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8635c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)       # 표준매개변수 처리\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel(30, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1fad6836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6398 - output_1_loss: 2.3376 - output_2_loss: 5.3598 - val_loss: 1.3607 - val_output_1_loss: 0.9834 - val_output_2_loss: 4.7563\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1705 - output_1_loss: 0.8685 - output_2_loss: 3.8881 - val_loss: 0.9535 - val_output_1_loss: 0.7075 - val_output_2_loss: 3.1673\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8836 - output_1_loss: 0.6790 - output_2_loss: 2.7249 - val_loss: 0.8195 - val_output_1_loss: 0.6535 - val_output_2_loss: 2.3132\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7824 - output_1_loss: 0.6323 - output_2_loss: 2.1340 - val_loss: 0.7518 - val_output_1_loss: 0.6227 - val_output_2_loss: 1.9139\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7275 - output_1_loss: 0.6037 - output_2_loss: 1.8425 - val_loss: 0.7101 - val_output_1_loss: 0.5987 - val_output_2_loss: 1.7125\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6912 - output_1_loss: 0.5809 - output_2_loss: 1.6838 - val_loss: 0.6815 - val_output_1_loss: 0.5799 - val_output_2_loss: 1.5967\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6639 - output_1_loss: 0.5619 - output_2_loss: 1.5815 - val_loss: 0.6589 - val_output_1_loss: 0.5638 - val_output_2_loss: 1.5156\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6419 - output_1_loss: 0.5459 - output_2_loss: 1.5058 - val_loss: 0.6404 - val_output_1_loss: 0.5501 - val_output_2_loss: 1.4526\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6242 - output_1_loss: 0.5329 - output_2_loss: 1.4454 - val_loss: 0.6256 - val_output_1_loss: 0.5394 - val_output_2_loss: 1.4017\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6100 - output_1_loss: 0.5228 - output_2_loss: 1.3954 - val_loss: 0.6129 - val_output_1_loss: 0.5300 - val_output_2_loss: 1.3591\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5992 - output_1_loss: 0.5181 - output_2_loss: 1.3288\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B933314DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9935d",
   "metadata": {},
   "source": [
    "사용하는 것은 동일하게 사용할 수 있지만 call() 메서드 안에 모델이 숨겨져 있기 때문에 케라스가 쉽게 분석 할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88d8eb",
   "metadata": {},
   "source": [
    "## 10.2.6 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0dfa193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a81bda2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8688 - val_loss: 0.7796\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7040 - val_loss: 0.6453\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6180 - val_loss: 0.6001\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5762 - val_loss: 0.5717\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5496 - val_loss: 0.5476\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5267 - val_loss: 0.5303\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5100 - val_loss: 0.5157\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4960 - val_loss: 0.5045\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4856 - val_loss: 0.4955\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4771 - val_loss: 0.4883\n",
      "162/162 [==============================] - 0s 957us/step - loss: 0.4842\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "47fb6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c769425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86507b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c0d32413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1b934bfe190>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9678b",
   "metadata": {},
   "source": [
    "## 10.2.7 콜백 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "87acef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4491390d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8688 - val_loss: 0.7796\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7040 - val_loss: 0.6453\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6180 - val_loss: 0.6001\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5762 - val_loss: 0.5717\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5496 - val_loss: 0.5476\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5267 - val_loss: 0.5303\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5100 - val_loss: 0.5157\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4960 - val_loss: 0.5045\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4856 - val_loss: 0.4955\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4771 - val_loss: 0.4883\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data = (X_valid, y_valid), callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model('my_keras_model.h5')      # 최상의 모델로 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "602911a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 923us/step - loss: 0.4842\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a6622aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4696 - val_loss: 0.4839\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4642 - val_loss: 0.4775\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4595 - val_loss: 0.4728\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4550 - val_loss: 0.4719\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4533 - val_loss: 0.4663\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4484 - val_loss: 0.4643\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4457 - val_loss: 0.4614\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4428 - val_loss: 0.4594\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4407 - val_loss: 0.4571\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4388 - val_loss: 0.4549\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4363 - val_loss: 0.4533\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4345 - val_loss: 0.4510\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4325 - val_loss: 0.4489\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4307 - val_loss: 0.4476\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4288 - val_loss: 0.4475\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.4446\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4450\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4244 - val_loss: 0.4423\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4412\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4211 - val_loss: 0.4415\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4195 - val_loss: 0.4401\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4190 - val_loss: 0.4385\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4369\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4164 - val_loss: 0.4346\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.4360\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4139 - val_loss: 0.4349\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4122 - val_loss: 0.4328\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4111 - val_loss: 0.4308\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4098 - val_loss: 0.4313\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4092 - val_loss: 0.4294\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4076 - val_loss: 0.4335\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4079 - val_loss: 0.4288\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4282\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4035 - val_loss: 0.4278\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4049 - val_loss: 0.4252\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.4256\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.4241\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4024 - val_loss: 0.4224\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3992 - val_loss: 0.4230\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3983 - val_loss: 0.4211\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3970 - val_loss: 0.4196\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.4201\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3948 - val_loss: 0.4172\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3942 - val_loss: 0.4157\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3931 - val_loss: 0.4160\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3923 - val_loss: 0.4149\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3912 - val_loss: 0.4145\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3904 - val_loss: 0.4123\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.4125\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3884 - val_loss: 0.4133\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3873 - val_loss: 0.4103\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.4117\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3859 - val_loss: 0.4083\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3847 - val_loss: 0.4076\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.4079\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3831 - val_loss: 0.4063\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3820 - val_loss: 0.4056\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3814 - val_loss: 0.4039\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3805 - val_loss: 0.4034\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3796 - val_loss: 0.4044\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3789 - val_loss: 0.4026\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3779 - val_loss: 0.4042\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3776 - val_loss: 0.4007\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.4021\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3756 - val_loss: 0.4013\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3752 - val_loss: 0.3989\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3746 - val_loss: 0.3987\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3729 - val_loss: 0.3997\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3724 - val_loss: 0.4011\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.3997\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3712 - val_loss: 0.3953\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3703 - val_loss: 0.3964\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3699 - val_loss: 0.3936\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3698 - val_loss: 0.3940\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3679 - val_loss: 0.3924\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3672 - val_loss: 0.3920\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3664 - val_loss: 0.3915\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3658 - val_loss: 0.3942\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3656 - val_loss: 0.3897\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3641 - val_loss: 0.3901\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3640 - val_loss: 0.3884\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.3912\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3622 - val_loss: 0.3890\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3621 - val_loss: 0.3879\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3605 - val_loss: 0.3879\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3601 - val_loss: 0.3863\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3851\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.3856\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3580 - val_loss: 0.3849\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3582 - val_loss: 0.3892\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3816\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.3905\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3831\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3870\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3590 - val_loss: 0.3804\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3551 - val_loss: 0.3898\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3607 - val_loss: 0.3803\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3831\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.3783\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3850\n"
     ]
    }
   ],
   "source": [
    "# 조기종료 구현\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00f82a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 981us/step - loss: 0.3682\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a45a7a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 콜백\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print('\\nval/train: {:.2f}'.format(logs['val_loss'] / logs['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a41ecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/363 [==========================>...] - ETA: 0s - loss: 0.3545\n",
      "val/train: 1.07\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3531 - val_loss: 0.3790\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c229199d",
   "metadata": {},
   "source": [
    "## 10.2.8 텐서보드를 이용한 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9b4b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2022_09_18-16_01_25'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbb9b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856b767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93ba053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8688 - val_loss: 0.7796\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7040 - val_loss: 0.6453\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6180 - val_loss: 0.6001\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5762 - val_loss: 0.5717\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5496 - val_loss: 0.5476\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5267 - val_loss: 0.5303\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5100 - val_loss: 0.5157\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4960 - val_loss: 0.5045\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4856 - val_loss: 0.4955\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4771 - val_loss: 0.4883\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4698 - val_loss: 0.4830\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4642 - val_loss: 0.4779\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4732\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4553 - val_loss: 0.4700\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4683\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4485 - val_loss: 0.4639\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4454 - val_loss: 0.4632\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4434 - val_loss: 0.4593\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4570\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4384 - val_loss: 0.4561\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4541\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4348 - val_loss: 0.4515\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4323 - val_loss: 0.4498\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4311 - val_loss: 0.4470\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4286 - val_loss: 0.4475\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4275 - val_loss: 0.4463\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4255 - val_loss: 0.4435\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4241 - val_loss: 0.4415\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4225 - val_loss: 0.4417\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4214 - val_loss: 0.4397\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab61043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ab9da13e41d11376\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ab9da13e41d11376\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b525ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2022_08_13-20_03_29'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "45ed8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bfc7ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "06862b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7432 - val_loss: 2.0988\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dd30f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000+1):\n",
    "        tf.summary.scalar('my_scalar', np.sin(step/10), step=step)\n",
    "        data = (np.random.randn(100)+2) * step /100\n",
    "        tf.summary.histogram('my_hist', data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3)\n",
    "        tf.summary.image('my_images', images * step / 1000, step=step)\n",
    "        texts = ['The step is ' + str(step), 'Its square is ' + str(step**2)]\n",
    "        tf.summary.text('my_text', texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 *2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio('my_audio', audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c0dae",
   "metadata": {},
   "source": [
    "# 10.3 신경망 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3487d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2f2989cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "067151f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytnal\\AppData\\Local\\Temp\\ipykernel_4816\\1709004121.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "718674a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2085 - val_loss: 0.6912\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6392 - val_loss: 0.5978\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5639 - val_loss: 0.5487\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.5207\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4968 - val_loss: 0.5010\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4797 - val_loss: 0.4917\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4785\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4583 - val_loss: 0.4713\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4522 - val_loss: 0.4655\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.4626\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4592\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4392 - val_loss: 0.4564\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4358 - val_loss: 0.4539\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.4510\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4296 - val_loss: 0.4496\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4449\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4246 - val_loss: 0.4453\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4223 - val_loss: 0.4405\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4200 - val_loss: 0.4390\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.4387\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4158 - val_loss: 0.4340\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4136 - val_loss: 0.4328\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4333\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.4295\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4287\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.4287\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4269\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.4231\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4003 - val_loss: 0.4225\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4204\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4208\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.4241\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.4213\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.4184\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4160\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.4150\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.4150\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.4108\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.4196\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.4159\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3826 - val_loss: 0.4086\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.4089\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.4053\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.4053\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.4040\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.4025\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.4015\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.4081\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.4021\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.4001\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.3988\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3705 - val_loss: 0.4023\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.3981\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.3947\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3980\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.3946\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.3957\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3939\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3974\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.3910\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3907\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3956\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3879\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.3898\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3873\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3573 - val_loss: 0.3883\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.3873\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.3867\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.3899\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3878\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3846\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.3835\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.3831\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3843\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3845\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3816\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.4064\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3504 - val_loss: 0.3812\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.3801\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3481 - val_loss: 0.3786\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.3845\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3895\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3815\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.3797\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3887\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3882\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.3790\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.3768\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3783\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.3772\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.3778\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3439 - val_loss: 0.3774\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.3769\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3746\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3785\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3919\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3756\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.3724\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3387 - val_loss: 0.3758\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.3734\n",
      "162/162 [==============================] - 0s 894us/step - loss: 0.3501\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "79f6e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c986a26b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.4266 - val_loss: 1.9376\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3169 - val_loss: 1.0370\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8530 - val_loss: 0.8178\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7292 - val_loss: 0.7415\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6829 - val_loss: 0.7035\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6573 - val_loss: 0.6819\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6391 - val_loss: 0.6626\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6244 - val_loss: 0.6455\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.6337\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6212\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5920 - val_loss: 0.6141\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5841 - val_loss: 0.6040\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5771 - val_loss: 0.5979\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - val_loss: 0.5913\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5654 - val_loss: 0.5852\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5608 - val_loss: 0.5811\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5564 - val_loss: 0.5774\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5524 - val_loss: 0.5730\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5491 - val_loss: 0.5701\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5463 - val_loss: 0.5671\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5435 - val_loss: 0.5645\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5411 - val_loss: 0.5620\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5388 - val_loss: 0.5609\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5371 - val_loss: 0.5581\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5354 - val_loss: 0.5566\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5339 - val_loss: 0.5553\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5536\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5313 - val_loss: 0.5525\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5301 - val_loss: 0.5512\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.5503\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5500\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5486\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5266 - val_loss: 0.5476\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5260 - val_loss: 0.5468\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 0.5464\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5249 - val_loss: 0.5460\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.5451\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 0.5449\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.5442\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 0.5437\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5225 - val_loss: 0.5433\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 0.5424\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5421\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5218 - val_loss: 0.5424\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5217 - val_loss: 0.5420\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5215 - val_loss: 0.5415\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5414\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.5408\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.5404\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5208 - val_loss: 0.5403\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5399\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.5397\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5395\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5204 - val_loss: 0.5394\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5201 - val_loss: 0.5396\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5199 - val_loss: 0.5393\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5201 - val_loss: 0.5390\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5200 - val_loss: 0.5390\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 0.5392\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5198 - val_loss: 0.5389\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5197 - val_loss: 0.5385\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5197 - val_loss: 0.5382\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5197 - val_loss: 0.5379\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5196 - val_loss: 0.5381\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5196 - val_loss: 0.5382\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5380\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.5378\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5377\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5377\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5194 - val_loss: 0.5377\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5376\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5192 - val_loss: 0.5374\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5192 - val_loss: 0.5376\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5378\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5376\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5192 - val_loss: 0.5375\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5193 - val_loss: 0.5374\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5192 - val_loss: 0.5372\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 0.5369\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5192 - val_loss: 0.5372\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5192 - val_loss: 0.5373\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5372\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5192 - val_loss: 0.5371\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5372\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5369\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5189 - val_loss: 0.5369\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5369\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5368\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5368\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5190 - val_loss: 0.5371\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5369\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5369\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5192 - val_loss: 0.5371\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5370\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5365\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5364\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5189 - val_loss: 0.5368\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5366\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5365\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5366\n",
      "121/121 [==============================] - 0s 900us/step - loss: 0.5130\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.7509 - val_loss: 1.8449\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3517 - val_loss: 1.0730\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9379 - val_loss: 0.8828\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8195 - val_loss: 0.8122\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7643 - val_loss: 0.7705\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7265 - val_loss: 0.7402\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6961 - val_loss: 0.7121\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6700 - val_loss: 0.6884\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6475 - val_loss: 0.6682\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6287 - val_loss: 0.6511\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.6372\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5979 - val_loss: 0.6238\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5857 - val_loss: 0.6135\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5751 - val_loss: 0.6043\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5660 - val_loss: 0.5948\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5582 - val_loss: 0.5891\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5515 - val_loss: 0.5829\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5456 - val_loss: 0.5775\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5405 - val_loss: 0.5719\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5360 - val_loss: 0.5704\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5326 - val_loss: 0.5656\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5619\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5261 - val_loss: 0.5608\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 0.5570\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5216 - val_loss: 0.5553\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.5546\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5181 - val_loss: 0.5521\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5165 - val_loss: 0.5522\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5152 - val_loss: 0.5515\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5140 - val_loss: 0.5496\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5132 - val_loss: 0.5483\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5123 - val_loss: 0.5482\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5111 - val_loss: 0.5450\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5109 - val_loss: 0.5453\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 0.5456\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5098 - val_loss: 0.5447\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.5432\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5088 - val_loss: 0.5426\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5084 - val_loss: 0.5423\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5083 - val_loss: 0.5423\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5076 - val_loss: 0.5435\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5076 - val_loss: 0.5424\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5420\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5069 - val_loss: 0.5406\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.5409\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5067 - val_loss: 0.5397\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5067 - val_loss: 0.5405\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 0.5418\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 0.5399\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5063 - val_loss: 0.5393\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5061 - val_loss: 0.5408\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5061 - val_loss: 0.5395\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.5395\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5058 - val_loss: 0.5387\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5057 - val_loss: 0.5405\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5056 - val_loss: 0.5391\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5056 - val_loss: 0.5401\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5056 - val_loss: 0.5388\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5061 - val_loss: 0.5388\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.5396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5056 - val_loss: 0.5394\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.5394\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.5397\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5374\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.5378\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.5384\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5053 - val_loss: 0.5377\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.5375\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.5383\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5052 - val_loss: 0.5370\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.5373\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5052 - val_loss: 0.5386\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.5391\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5376\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.5373\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.5377\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5051 - val_loss: 0.5370\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5052 - val_loss: 0.5377\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5050 - val_loss: 0.5377\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5385\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.5375\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5050 - val_loss: 0.5374\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5052 - val_loss: 0.5369\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.5370\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5374\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5050 - val_loss: 0.5384\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5384\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5052 - val_loss: 0.5381\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5052 - val_loss: 0.5371\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5382\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5050 - val_loss: 0.5370\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5052 - val_loss: 0.5371\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5050 - val_loss: 0.5362\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5370\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5378\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5386\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.5371\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5384\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.5373\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5374\n",
      "121/121 [==============================] - 0s 935us/step - loss: 0.5414\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.1337 - val_loss: 1.6098\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9815 - val_loss: 0.7247\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6153 - val_loss: 0.5718\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5450 - val_loss: 0.5436\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5309 - val_loss: 0.5392\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5373\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5270 - val_loss: 0.5372\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5264 - val_loss: 0.5382\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5263 - val_loss: 0.5381\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5261 - val_loss: 0.5375\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5257 - val_loss: 0.5372\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5257 - val_loss: 0.5374\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5256 - val_loss: 0.5370\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5253 - val_loss: 0.5375\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5252 - val_loss: 0.5367\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.5375\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.5369\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 0.5373\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.5371\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 0.5388\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 0.5373\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 0.5378\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 0.5369\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 0.5374\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 0.5368\n",
      "121/121 [==============================] - 0s 988us/step - loss: 0.5008\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2634 - val_loss: 0.6593\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6018 - val_loss: 0.5920\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5645 - val_loss: 0.5701\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5434 - val_loss: 0.5610\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5348 - val_loss: 0.5524\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5306 - val_loss: 0.5434\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5450\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5222 - val_loss: 0.5403\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 0.5396\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 0.5421\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 0.5426\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5368\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 0.5405\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 0.5360\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5220 - val_loss: 0.5495\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 0.5370\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5224 - val_loss: 0.5364\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5468\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5221 - val_loss: 0.5500\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5208 - val_loss: 0.5437\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 0.5376\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5209 - val_loss: 0.5532\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.5375\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 0.5515\n",
      "121/121 [==============================] - 0s 788us/step - loss: 0.5333\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2097 - val_loss: 0.6030\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.5732\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5472 - val_loss: 0.5733\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 0.5863\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7062 - val_loss: 0.5674\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5181 - val_loss: 0.5592\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5222 - val_loss: 0.5532\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5480\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5121 - val_loss: 0.5883\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5432\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5343 - val_loss: 0.5469\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5401 - val_loss: 0.5401\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5170 - val_loss: 0.5403\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.5363\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.5502\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5127 - val_loss: 0.5372\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5099 - val_loss: 0.5483\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5137 - val_loss: 0.5447\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 0.5533\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5129 - val_loss: 0.5731\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6384 - val_loss: 0.5463\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5085 - val_loss: 0.5499\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6195 - val_loss: 0.5505\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5795 - val_loss: 0.5464\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5401\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4886 - val_loss: 2.3864\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5617 - val_loss: 35.0000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 75.6994 - val_loss: 577.2287\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1244.2172 - val_loss: 9906.1729\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 22061.5156 - val_loss: 169953.5938\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 348026.0938 - val_loss: 2953270.2500\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6108293.0000 - val_loss: 50191128.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 118249104.0000 - val_loss: 859032768.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1924769920.0000 - val_loss: 14724274176.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 33560887296.0000 - val_loss: 252557492224.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 592784588800.0000 - val_loss: 4325237850112.0000\n",
      "121/121 [==============================] - 0s 885us/step - loss: 3648492666880.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4877 - val_loss: 1.5434\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0755 - val_loss: 1.0010\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8353 - val_loss: 0.8185\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7526 - val_loss: 0.7513\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7115 - val_loss: 0.7158\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6835 - val_loss: 0.6897\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6611 - val_loss: 0.6680\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6417 - val_loss: 0.6493\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6247 - val_loss: 0.6329\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.6186\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5955 - val_loss: 0.6051\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5829 - val_loss: 0.5928\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5711 - val_loss: 0.5820\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5606 - val_loss: 0.5719\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5509 - val_loss: 0.5632\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 0.5552\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 0.5472\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 0.5401\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5185 - val_loss: 0.5354\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5121 - val_loss: 0.5275\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5059 - val_loss: 0.5218\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5002 - val_loss: 0.5169\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4948 - val_loss: 0.5123\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.5081\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5039\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.4993\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.4955\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.4923\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.4898\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 0.4861\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.4838\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 0.4806\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.4784\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.4758\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.4735\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.4722\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4476 - val_loss: 0.4702\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4453 - val_loss: 0.4687\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.4660\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4413 - val_loss: 0.4639\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4622\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4375 - val_loss: 0.4604\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.4592\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.4580\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4325 - val_loss: 0.4563\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 0.4560\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.4536\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.4525\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.4505\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 0.4503\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4236 - val_loss: 0.4484\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4228 - val_loss: 0.4473\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.4461\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.4456\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.4450\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.4442\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.4429\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.4421\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.4410\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4136 - val_loss: 0.4397\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.4383\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 0.4386\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.4363\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.4365\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.4354\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.4346\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.4348\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4062 - val_loss: 0.4339\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4053 - val_loss: 0.4328\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.4319\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4037 - val_loss: 0.4314\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.4310\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.4298\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4012 - val_loss: 0.4303\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4005 - val_loss: 0.4289\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.4280\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.4272\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3984 - val_loss: 0.4268\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4255\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3971 - val_loss: 0.4254\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3963 - val_loss: 0.4251\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3955 - val_loss: 0.4249\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3947 - val_loss: 0.4245\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.4232\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3935 - val_loss: 0.4229\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.4217\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3922 - val_loss: 0.4216\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.4208\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.4198\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3900 - val_loss: 0.4211\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3897 - val_loss: 0.4201\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.4190\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4192\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.4179\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.4174\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.4165\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4163\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4159\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.4153\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 0.4147\n",
      "121/121 [==============================] - 0s 970us/step - loss: 0.3911\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.9368 - val_loss: 1.6065\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1437 - val_loss: 0.8921\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7853 - val_loss: 0.7361\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6921 - val_loss: 0.6917\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6535 - val_loss: 0.6676\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6282 - val_loss: 0.6484\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6085 - val_loss: 0.6315\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5920 - val_loss: 0.6171\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5775 - val_loss: 0.6037\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5650 - val_loss: 0.5923\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5539 - val_loss: 0.5819\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 0.5721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.5641\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 0.5561\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5196 - val_loss: 0.5495\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 0.5424\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.5365\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5007 - val_loss: 0.5310\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.5267\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4905 - val_loss: 0.5209\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.5168\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4817 - val_loss: 0.5118\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4778 - val_loss: 0.5082\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.5045\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.5007\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4976\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4640 - val_loss: 0.4943\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.4911\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4886\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.4857\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4833\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.4802\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4476 - val_loss: 0.4783\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.4757\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 0.4734\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.4712\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4389 - val_loss: 0.4692\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4670\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4351 - val_loss: 0.4646\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.4629\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4314 - val_loss: 0.4616\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4297 - val_loss: 0.4599\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4282 - val_loss: 0.4581\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4567\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4549\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4534\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4223 - val_loss: 0.4524\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 0.4507\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4195 - val_loss: 0.4494\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.4484\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 0.4470\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 0.4457\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.4445\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.4441\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.4430\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4110 - val_loss: 0.4423\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.4409\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.4399\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4082 - val_loss: 0.4391\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4377\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.4368\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4053 - val_loss: 0.4363\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.4349\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4036 - val_loss: 0.4346\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.4338\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4325\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 0.4322\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4004 - val_loss: 0.4313\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3995 - val_loss: 0.4309\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3988 - val_loss: 0.4296\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 0.4294\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.4287\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.4277\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3958 - val_loss: 0.4272\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.4266\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.4260\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.4253\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.4251\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.4240\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3917 - val_loss: 0.4237\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3910 - val_loss: 0.4232\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3903 - val_loss: 0.4228\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3897 - val_loss: 0.4223\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.4214\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4211\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.4205\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.4204\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.4202\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.4189\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.4192\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3847 - val_loss: 0.4187\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.4181\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.4177\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.4169\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3827 - val_loss: 0.4162\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.4157\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.4151\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.4153\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.4142\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3797 - val_loss: 0.4142\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4117\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.8257 - val_loss: 1.4896\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1736 - val_loss: 0.9890\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8933 - val_loss: 0.8328\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8051 - val_loss: 0.7731\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7621 - val_loss: 0.7397\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7326 - val_loss: 0.7158\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7079 - val_loss: 0.6956\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6868 - val_loss: 0.6779\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6678 - val_loss: 0.6618\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6502 - val_loss: 0.6463\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6344 - val_loss: 0.6324\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6194 - val_loss: 0.6194\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6056 - val_loss: 0.6079\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5932 - val_loss: 0.5967\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5814 - val_loss: 0.5869\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5710 - val_loss: 0.5771\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5613 - val_loss: 0.5686\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5519 - val_loss: 0.5608\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5440 - val_loss: 0.5539\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5362 - val_loss: 0.5474\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 0.5413\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5353\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5168 - val_loss: 0.5300\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5109 - val_loss: 0.5251\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5060 - val_loss: 0.5200\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5013 - val_loss: 0.5163\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4968 - val_loss: 0.5123\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4927 - val_loss: 0.5086\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.5048\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5019\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.4986\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4790 - val_loss: 0.4959\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.4931\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.4903\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.4879\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.4861\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.4835\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.4814\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.4788\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.4772\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.4763\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.4736\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4536 - val_loss: 0.4719\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.4710\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 0.4680\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4483 - val_loss: 0.4672\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4469 - val_loss: 0.4656\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.4641\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4437 - val_loss: 0.4630\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4425 - val_loss: 0.4616\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4606\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4397 - val_loss: 0.4595\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.4576\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4373 - val_loss: 0.4566\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.4559\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4543\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.4548\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.4524\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 0.4514\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4302 - val_loss: 0.4502\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.4492\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 0.4488\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.4479\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4261 - val_loss: 0.4467\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.4456\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 0.4454\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 0.4440\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4223 - val_loss: 0.4433\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4213 - val_loss: 0.4427\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4205 - val_loss: 0.4417\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4196 - val_loss: 0.4411\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.4405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4179 - val_loss: 0.4397\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 0.4388\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4161 - val_loss: 0.4379\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4153 - val_loss: 0.4372\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.4364\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 0.4365\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4129 - val_loss: 0.4349\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4121 - val_loss: 0.4347\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 0.4335\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4107 - val_loss: 0.4331\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 0.4332\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.4319\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4085 - val_loss: 0.4317\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.4312\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.4302\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4062 - val_loss: 0.4301\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.4298\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4051 - val_loss: 0.4285\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4041 - val_loss: 0.4277\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4035 - val_loss: 0.4277\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.4266\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4021 - val_loss: 0.4260\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 0.4252\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.4254\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4003 - val_loss: 0.4250\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3996 - val_loss: 0.4238\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.4233\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3982 - val_loss: 0.4237\n",
      "121/121 [==============================] - 0s 924us/step - loss: 0.3960\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1911 - val_loss: 1.4620\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0073 - val_loss: 1.0825\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8542 - val_loss: 0.9296\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7936 - val_loss: 0.8572\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7578 - val_loss: 0.8123\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7326 - val_loss: 0.7811\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7118 - val_loss: 0.7558\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6941 - val_loss: 0.7356\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6784 - val_loss: 0.7170\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6637 - val_loss: 0.7007\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6504 - val_loss: 0.6849\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6382 - val_loss: 0.6709\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6265 - val_loss: 0.6576\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6161 - val_loss: 0.6457\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.6350\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5965 - val_loss: 0.6250\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5872 - val_loss: 0.6147\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5788 - val_loss: 0.6057\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5706 - val_loss: 0.5980\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5629 - val_loss: 0.5888\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5553 - val_loss: 0.5809\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5489 - val_loss: 0.5740\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5425 - val_loss: 0.5680\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5366 - val_loss: 0.5617\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 0.5564\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 0.5508\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5460\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5172 - val_loss: 0.5418\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 0.5383\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5091 - val_loss: 0.5337\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5057 - val_loss: 0.5307\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 0.5269\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4993 - val_loss: 0.5239\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4962 - val_loss: 0.5212\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4938 - val_loss: 0.5189\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.5166\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.5149\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.5129\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4847 - val_loss: 0.5107\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.5092\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.5071\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.5057\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.5039\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5026\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5009\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.5006\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.4988\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 0.4975\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 0.4957\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 0.4947\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.4932\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4664 - val_loss: 0.4922\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.4909\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.4903\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.4898\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.4882\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.4873\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.4864\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.4860\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.4845\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.4834\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 0.4830\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.4814\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.4808\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.4800\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4530 - val_loss: 0.4798\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.4791\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.4787\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4505 - val_loss: 0.4769\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4497 - val_loss: 0.4764\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.4753\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4753\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.4738\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.4742\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4458 - val_loss: 0.4727\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4448 - val_loss: 0.4717\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4709\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.4704\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.4697\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4693\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.4687\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4408 - val_loss: 0.4685\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4678\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4396 - val_loss: 0.4669\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4389 - val_loss: 0.4663\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.4657\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4651\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4370 - val_loss: 0.4647\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4364 - val_loss: 0.4637\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4638\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4352 - val_loss: 0.4631\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4344 - val_loss: 0.4622\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4341 - val_loss: 0.4619\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4611\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4605\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.4604\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4316 - val_loss: 0.4591\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4598\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4584\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4299 - val_loss: 0.4581\n",
      "121/121 [==============================] - 0s 853us/step - loss: 0.4544\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.8820 - val_loss: 2.7137\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3276 - val_loss: 1.9396\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6240 - val_loss: 1.4114\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2452 - val_loss: 1.1471\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0369 - val_loss: 0.9879\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.8980\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8544 - val_loss: 0.8462\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8138 - val_loss: 0.8142\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7857 - val_loss: 0.7920\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7649 - val_loss: 0.7750\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7474 - val_loss: 0.7607\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7316 - val_loss: 0.7476\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7186 - val_loss: 0.7362\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7063 - val_loss: 0.7253\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6953 - val_loss: 0.7155\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6851 - val_loss: 0.7061\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6755 - val_loss: 0.6973\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6663 - val_loss: 0.6889\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6575 - val_loss: 0.6816\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6491 - val_loss: 0.6731\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6416 - val_loss: 0.6652\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6337 - val_loss: 0.6579\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6262 - val_loss: 0.6509\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.6441\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 0.6376\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6054 - val_loss: 0.6314\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6252\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5928 - val_loss: 0.6196\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5868 - val_loss: 0.6136\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5811 - val_loss: 0.6078\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - val_loss: 0.6026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5700 - val_loss: 0.5973\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5648 - val_loss: 0.5920\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5599 - val_loss: 0.5872\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5551 - val_loss: 0.5824\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5506 - val_loss: 0.5779\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5462 - val_loss: 0.5736\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5420 - val_loss: 0.5692\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 0.5655\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5341 - val_loss: 0.5615\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5303 - val_loss: 0.5580\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 0.5545\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.5511\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 0.5480\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5169 - val_loss: 0.5448\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5140 - val_loss: 0.5414\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 0.5388\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5084 - val_loss: 0.5359\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5057 - val_loss: 0.5334\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5032 - val_loss: 0.5305\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5007 - val_loss: 0.5283\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4981 - val_loss: 0.5259\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4961 - val_loss: 0.5232\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4938 - val_loss: 0.5211\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5191\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4892 - val_loss: 0.5171\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4876 - val_loss: 0.5147\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4855 - val_loss: 0.5127\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4837 - val_loss: 0.5108\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5088\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5076\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.5056\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.5039\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4748 - val_loss: 0.5023\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4731 - val_loss: 0.5005\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.4993\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4700 - val_loss: 0.4978\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.4960\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.4947\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.4933\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.4920\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4634 - val_loss: 0.4907\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4621 - val_loss: 0.4895\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.4882\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.4874\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4585 - val_loss: 0.4862\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4573 - val_loss: 0.4848\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4562 - val_loss: 0.4844\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4828\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4540 - val_loss: 0.4818\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4530 - val_loss: 0.4809\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4518 - val_loss: 0.4800\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4510 - val_loss: 0.4793\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 0.4783\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.4775\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4766\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.4759\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4462 - val_loss: 0.4753\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4452 - val_loss: 0.4742\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4443 - val_loss: 0.4736\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 0.4729\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4427 - val_loss: 0.4723\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.4712\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.4708\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4403 - val_loss: 0.4697\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4394 - val_loss: 0.4694\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4681\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4380 - val_loss: 0.4678\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.4675\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.4664\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4751\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.8786 - val_loss: 1.6140\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3020 - val_loss: 1.1121\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 0.9443\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8859 - val_loss: 0.8534\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8209 - val_loss: 0.7954\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7776 - val_loss: 0.7573\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7468 - val_loss: 0.7298\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7226 - val_loss: 0.7093\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7029 - val_loss: 0.6914\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6856 - val_loss: 0.6767\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6714 - val_loss: 0.6637\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6581 - val_loss: 0.6522\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6460 - val_loss: 0.6415\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6351 - val_loss: 0.6316\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6247 - val_loss: 0.6227\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6153 - val_loss: 0.6139\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6065 - val_loss: 0.6060\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5982 - val_loss: 0.5985\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 0.5917\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5835 - val_loss: 0.5856\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5769 - val_loss: 0.5795\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5706 - val_loss: 0.5736\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5648 - val_loss: 0.5681\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5590 - val_loss: 0.5632\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5536 - val_loss: 0.5581\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5488 - val_loss: 0.5537\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5441 - val_loss: 0.5496\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 0.5454\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5354 - val_loss: 0.5413\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 0.5380\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5345\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 0.5313\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5278\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5175 - val_loss: 0.5251\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5144 - val_loss: 0.5224\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5113 - val_loss: 0.5199\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5085 - val_loss: 0.5172\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5055 - val_loss: 0.5147\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5123\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5007 - val_loss: 0.5099\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4981 - val_loss: 0.5085\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 0.5057\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4938 - val_loss: 0.5035\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.5020\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4894 - val_loss: 0.4993\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.4978\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.4961\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.4943\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.4928\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4800 - val_loss: 0.4915\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.4898\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.4887\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.4864\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.4852\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.4841\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.4826\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.4827\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.4802\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.4790\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 0.4778\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4633 - val_loss: 0.4767\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4620 - val_loss: 0.4762\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.4754\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.4737\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4585 - val_loss: 0.4727\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.4722\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.4710\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.4700\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.4694\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.4682\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.4678\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4510 - val_loss: 0.4671\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4500 - val_loss: 0.4660\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4489 - val_loss: 0.4653\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4642\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4471 - val_loss: 0.4634\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4462 - val_loss: 0.4626\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.4625\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4443 - val_loss: 0.4612\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.4609\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4426 - val_loss: 0.4600\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.4594\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.4593\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.4582\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4579\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.4572\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 0.4565\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4370 - val_loss: 0.4565\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 0.4562\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 0.4550\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.4545\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.4540\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4332 - val_loss: 0.4533\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4525\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4319 - val_loss: 0.4520\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4519\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 0.4519\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4299 - val_loss: 0.4506\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 0.4501\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.4500\n",
      "121/121 [==============================] - 0s 928us/step - loss: 0.4109\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0507 - val_loss: 0.7876\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6815 - val_loss: 0.6599\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6155 - val_loss: 0.6179\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5810 - val_loss: 0.5902\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5605 - val_loss: 0.5736\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5475 - val_loss: 0.5617\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5390 - val_loss: 0.5572\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5487\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5465\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5271 - val_loss: 0.5451\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 0.5467\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 0.5404\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 0.5418\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.5386\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5220 - val_loss: 0.5452\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 0.5386\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5219 - val_loss: 0.5379\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5203 - val_loss: 0.5443\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5212 - val_loss: 0.5471\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5412\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5219 - val_loss: 0.5373\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5204 - val_loss: 0.5461\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5203 - val_loss: 0.5375\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5202 - val_loss: 0.5452\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5213 - val_loss: 0.5418\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5218 - val_loss: 0.5375\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5216 - val_loss: 0.5366\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5211 - val_loss: 0.5377\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5217 - val_loss: 0.5363\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5361\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5206 - val_loss: 0.5404\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5219 - val_loss: 0.5359\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5209 - val_loss: 0.5413\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5413\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5369\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.5403\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5392\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5211 - val_loss: 0.5398\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5206 - val_loss: 0.5384\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5208 - val_loss: 0.5358\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5199 - val_loss: 0.5363\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5215 - val_loss: 0.5378\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5213 - val_loss: 0.5358\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5206 - val_loss: 0.5451\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5202 - val_loss: 0.5416\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5394\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5221 - val_loss: 0.5373\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5367\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5353\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5213 - val_loss: 0.5367\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5202 - val_loss: 0.5415\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5219 - val_loss: 0.5378\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5222 - val_loss: 0.5364\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5218 - val_loss: 0.5358\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5202 - val_loss: 0.5377\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5361\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5216 - val_loss: 0.5369\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5216 - val_loss: 0.5382\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5219 - val_loss: 0.5369\n",
      "121/121 [==============================] - 0s 936us/step - loss: 0.5122\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4841 - val_loss: 0.6809\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5851 - val_loss: 0.6260\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6341 - val_loss: 0.6286\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5609 - val_loss: 0.6211\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6905 - val_loss: 0.6315\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5567 - val_loss: 0.6162\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5578 - val_loss: 0.5878\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6355 - val_loss: 0.5726\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.5571\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5136 - val_loss: 0.5564\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5634 - val_loss: 0.5651\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5798 - val_loss: 0.5545\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5518 - val_loss: 0.5588\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5812 - val_loss: 0.5510\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5467 - val_loss: 0.5599\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5581 - val_loss: 0.5490\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5151 - val_loss: 0.5425\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.5515\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5119 - val_loss: 0.5434\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.5679\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5930 - val_loss: 0.5608\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5183 - val_loss: 0.5665\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6257 - val_loss: 0.5807\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6829 - val_loss: 0.5679\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6060 - val_loss: 0.5658\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6230 - val_loss: 0.5592\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5941 - val_loss: 0.5568\n",
      "121/121 [==============================] - 0s 903us/step - loss: 0.5466\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8030 - val_loss: 0.6250\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5956 - val_loss: 0.6260\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7003 - val_loss: 0.9809\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3349 - val_loss: 3.0800\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.2160 - val_loss: 17.8864\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 35.7441 - val_loss: 114.4311\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 236.6070 - val_loss: 750.7871\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1658.1501 - val_loss: 4949.7383\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10749.8613 - val_loss: 32712.1152\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 71508.8672 - val_loss: 216476.6562\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 480108.5000 - val_loss: 1429748.8750\n",
      "121/121 [==============================] - 0s 894us/step - loss: 1207496.2500\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1189 - val_loss: 0.6280\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.5436\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5145 - val_loss: 0.5167\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4914 - val_loss: 0.5054\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4816 - val_loss: 0.5181\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4759 - val_loss: 0.4882\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4733 - val_loss: 0.5109\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4624 - val_loss: 0.4786\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.4719\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4799\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.4770\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4450 - val_loss: 0.4676\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4510 - val_loss: 0.4867\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4568\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4944\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4523\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4314 - val_loss: 0.4496\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4534\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4748\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 0.4555\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4353 - val_loss: 0.4571\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4528\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4435\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4436\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4347\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.4338\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4384\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4285\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.4255\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.4255\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.4226\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.4175\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4191\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.4138\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.4180\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.4221\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4148\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.4096\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.4067\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.4069\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.4032\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.4012\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4011\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.4012\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.4000\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.4027\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.3966\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3680 - val_loss: 0.3991\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.3899\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.3906\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.5567\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.3903\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3923\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3956\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3916\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.3961\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.4001\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.3945\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.3887\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3824\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.4383\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.3886\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.3848\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.4312\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.3753\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.3771\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.3885\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.3857\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3793\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.3714\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3730\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.4057\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.3735\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.3709\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3884\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3369 - val_loss: 0.3749\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.3757\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.3909\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3708\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3338 - val_loss: 0.3680\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3327 - val_loss: 0.3669\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.3642\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3313 - val_loss: 0.3723\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3281 - val_loss: 0.3735\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.3758\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3293 - val_loss: 0.3625\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.4188\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3589\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3674\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3297 - val_loss: 0.3617\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.5133\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3315 - val_loss: 0.3667\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.3664\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3595\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 0.3660\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3678\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3684\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.3625\n",
      "121/121 [==============================] - 0s 997us/step - loss: 0.3251\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9603 - val_loss: 0.7601\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5723 - val_loss: 0.5687\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6598 - val_loss: 0.5574\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5053\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.4809\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.4728\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4302 - val_loss: 0.4606\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.4556\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4534\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4155 - val_loss: 0.4448\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4420\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.4409\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.4375\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.4419\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4328\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.4307\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.4251\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.4269\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4239\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4180\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.4177\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.4194\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.4162\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.4146\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.4279\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.4103\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.4111\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.4111\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.4087\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.4099\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.4047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3635 - val_loss: 0.4056\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.4034\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.4064\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.4096\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.4075\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.4008\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.4005\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 0.4000\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.4015\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.4007\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.4045\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.3977\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.4006\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.3949\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3524 - val_loss: 0.3981\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3949\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3486 - val_loss: 0.3933\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.3953\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.4270\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3931\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.3924\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3982\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3898\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3462 - val_loss: 0.5892\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3931\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3907\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.3918\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.3952\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3437 - val_loss: 0.3885\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3406 - val_loss: 0.3932\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3409 - val_loss: 0.3890\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.4299\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.3863\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3868\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3841\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.4508\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3876\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 0.3851\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3838\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.4126\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3862\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.3820\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.3825\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3836\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.3807\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.4070\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.3795\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 0.3831\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.3811\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3323 - val_loss: 0.3803\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.3837\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.3869\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3772\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.3804\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3313 - val_loss: 0.3871\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3775\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3293 - val_loss: 0.3749\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.3805\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3280 - val_loss: 0.3797\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3827\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3270 - val_loss: 0.4104\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3286 - val_loss: 0.3767\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.3804\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3732\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.3721\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3269 - val_loss: 0.3894\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3770\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 0.3815\n",
      "121/121 [==============================] - 0s 927us/step - loss: 0.3546\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1651 - val_loss: 4.0054\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9.6948 - val_loss: 9.7010\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 318.5045 - val_loss: 23.2468\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 79.4705 - val_loss: 1.4145\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9968 - val_loss: 0.8420\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7610 - val_loss: 0.5806\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7557 - val_loss: 0.5117\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.7310 - val_loss: 0.5437\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8050 - val_loss: 0.4859\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5266 - val_loss: 0.9644\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4558 - val_loss: 0.5091\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4611 - val_loss: 0.4488\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6019 - val_loss: 0.4439\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8207 - val_loss: 0.4315\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.4520\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5942 - val_loss: 0.5108\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4923 - val_loss: 0.4190\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.4341\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4573 - val_loss: 1.6614\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5801 - val_loss: 0.4423\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6214 - val_loss: 0.4113\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5010\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.4020\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7166 - val_loss: 0.4994\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8239 - val_loss: 0.4024\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.4726\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5084 - val_loss: 0.5978\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5945 - val_loss: 0.9255\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4800 - val_loss: 0.4248\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7958 - val_loss: 0.4062\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5826 - val_loss: 0.4490\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.7001\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.4006\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8642 - val_loss: 0.4422\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 0.8873\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4859 - val_loss: 0.6530\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.7739\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4023\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9083 - val_loss: 0.4500\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4051\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3984 - val_loss: 0.4248\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3955 - val_loss: 0.9924\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6579 - val_loss: 0.3975\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6119 - val_loss: 0.4247\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.8789\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2586 - val_loss: 0.3857\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7659 - val_loss: 0.3887\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3881 - val_loss: 0.3925\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4704 - val_loss: 0.3832\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8882 - val_loss: 0.4499\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3997\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.3884\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.5663\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4054 - val_loss: 0.3780\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.3847\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.3904\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8919 - val_loss: 0.3825\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3965\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.3741\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.3821\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4773 - val_loss: 0.3742\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6078 - val_loss: 0.3883\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.4841\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4181 - val_loss: 0.5020\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.4024\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4225\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 0.4735\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.4142\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5507 - val_loss: 1.2206\n",
      "121/121 [==============================] - 0s 894us/step - loss: 1.0249\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.9748 - val_loss: 2.8893\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.1589 - val_loss: 1.8998\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5311 - val_loss: 1.5276\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2942 - val_loss: 1.3142\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1565 - val_loss: 1.1654\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0568 - val_loss: 1.0607\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9800 - val_loss: 0.9818\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9186 - val_loss: 0.9209\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8691 - val_loss: 0.8719\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8292 - val_loss: 0.8329\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7967 - val_loss: 0.8005\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7703 - val_loss: 0.7747\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7484 - val_loss: 0.7531\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7305 - val_loss: 0.7353\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7153 - val_loss: 0.7204\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7024 - val_loss: 0.7081\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6915 - val_loss: 0.6973\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6821 - val_loss: 0.6879\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6735 - val_loss: 0.6799\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6659 - val_loss: 0.6727\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6588 - val_loss: 0.6661\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6523 - val_loss: 0.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6463 - val_loss: 0.6544\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6405 - val_loss: 0.6489\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6352 - val_loss: 0.6438\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6301 - val_loss: 0.6389\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.6342\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6203 - val_loss: 0.6296\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.6253\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6111 - val_loss: 0.6209\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6068 - val_loss: 0.6168\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6128\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5985 - val_loss: 0.6088\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5943 - val_loss: 0.6051\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 0.6014\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5868 - val_loss: 0.5979\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 0.5945\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5794 - val_loss: 0.5913\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5760 - val_loss: 0.5879\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - val_loss: 0.5846\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5691 - val_loss: 0.5814\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5659 - val_loss: 0.5784\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5627 - val_loss: 0.5753\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5596 - val_loss: 0.5724\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5565 - val_loss: 0.5695\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5534 - val_loss: 0.5668\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5506 - val_loss: 0.5641\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5476 - val_loss: 0.5616\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5448 - val_loss: 0.5588\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5420 - val_loss: 0.5563\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5390 - val_loss: 0.5541\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5367 - val_loss: 0.5514\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5339 - val_loss: 0.5491\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 0.5469\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.5447\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 0.5424\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.5403\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5215 - val_loss: 0.5381\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5190 - val_loss: 0.5361\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5168 - val_loss: 0.5340\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5147 - val_loss: 0.5319\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5124 - val_loss: 0.5300\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.5279\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5082 - val_loss: 0.5260\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5062 - val_loss: 0.5243\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.5226\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5022 - val_loss: 0.5211\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5005 - val_loss: 0.5193\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4986 - val_loss: 0.5175\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4967 - val_loss: 0.5160\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.5143\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4932 - val_loss: 0.5128\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5115\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4899 - val_loss: 0.5102\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4883 - val_loss: 0.5085\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.5073\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4853 - val_loss: 0.5058\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.5045\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4823 - val_loss: 0.5031\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5020\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4793 - val_loss: 0.5007\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.4995\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.4984\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4754 - val_loss: 0.4971\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.4959\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.4948\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4716 - val_loss: 0.4937\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.4928\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4692 - val_loss: 0.4915\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4909\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4898\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4657 - val_loss: 0.4887\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.4877\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4637 - val_loss: 0.4868\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4857\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4617 - val_loss: 0.4849\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.4841\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4598 - val_loss: 0.4833\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.4823\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4816\n",
      "121/121 [==============================] - 0s 867us/step - loss: 0.4689\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.9086 - val_loss: 3.0610\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1413 - val_loss: 1.6254\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3523 - val_loss: 1.1865\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0829 - val_loss: 1.0158\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9626 - val_loss: 0.9212\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8881 - val_loss: 0.8614\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8377 - val_loss: 0.8205\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8010 - val_loss: 0.7926\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7744 - val_loss: 0.7722\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 0.7562\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7364 - val_loss: 0.7437\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7222 - val_loss: 0.7328\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7100 - val_loss: 0.7233\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6993 - val_loss: 0.7145\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6896 - val_loss: 0.7064\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6807 - val_loss: 0.6988\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6724 - val_loss: 0.6917\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6646 - val_loss: 0.6849\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6575 - val_loss: 0.6792\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6507 - val_loss: 0.6726\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6447 - val_loss: 0.6675\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6384 - val_loss: 0.6618\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6330 - val_loss: 0.6571\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6276 - val_loss: 0.6519\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6227 - val_loss: 0.6473\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6178 - val_loss: 0.6431\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 0.6387\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.6344\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 0.6308\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.6269\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5964 - val_loss: 0.6231\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5924 - val_loss: 0.6193\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5886 - val_loss: 0.6157\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5849 - val_loss: 0.6124\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5813 - val_loss: 0.6092\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5778 - val_loss: 0.6056\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5743 - val_loss: 0.6028\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5709 - val_loss: 0.5994\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5674 - val_loss: 0.5959\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5642 - val_loss: 0.5926\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5607 - val_loss: 0.5897\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5573 - val_loss: 0.5867\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5541 - val_loss: 0.5835\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5508 - val_loss: 0.5804\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5474 - val_loss: 0.5772\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5444 - val_loss: 0.5742\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 0.5715\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 0.5684\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5347 - val_loss: 0.5653\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.5625\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 0.5595\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5256 - val_loss: 0.5564\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5537\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 0.5513\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5169 - val_loss: 0.5482\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5138 - val_loss: 0.5452\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5112 - val_loss: 0.5425\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 0.5398\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5055 - val_loss: 0.5373\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 0.5346\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4999 - val_loss: 0.5320\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.5304\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 0.5271\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4923 - val_loss: 0.5248\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.5227\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4877 - val_loss: 0.5200\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.5185\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4830 - val_loss: 0.5155\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4807 - val_loss: 0.5137\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5113\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5092\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4745 - val_loss: 0.5074\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.5057\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.5042\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 0.5020\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.5004\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.4990\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.4971\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.4957\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4598 - val_loss: 0.4945\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.4925\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4564 - val_loss: 0.4914\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.4896\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.4883\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.4866\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.4856\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4494 - val_loss: 0.4844\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4482 - val_loss: 0.4832\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4469 - val_loss: 0.4817\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4456 - val_loss: 0.4809\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4446 - val_loss: 0.4796\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.4783\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.4774\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.4761\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4404 - val_loss: 0.4751\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4743\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4734\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4727\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 0.4717\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 0.4711\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4731\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.3892 - val_loss: 3.3514\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5659 - val_loss: 1.8330\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4062 - val_loss: 1.1594\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 0.9691\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8691 - val_loss: 0.8819\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8120 - val_loss: 0.8232\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7763 - val_loss: 0.7819\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7511 - val_loss: 0.7525\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7324 - val_loss: 0.7300\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7173 - val_loss: 0.7123\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7051 - val_loss: 0.6986\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6944 - val_loss: 0.6870\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6847 - val_loss: 0.6768\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6762 - val_loss: 0.6685\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6682 - val_loss: 0.6608\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6609 - val_loss: 0.6540\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6540 - val_loss: 0.6476\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6476 - val_loss: 0.6417\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6413 - val_loss: 0.6365\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6354 - val_loss: 0.6313\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6297 - val_loss: 0.6263\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6240 - val_loss: 0.6213\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6186 - val_loss: 0.6167\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6132 - val_loss: 0.6119\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6073\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 0.6032\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5977 - val_loss: 0.5988\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5926 - val_loss: 0.5946\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5876 - val_loss: 0.5900\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5826 - val_loss: 0.5856\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5775 - val_loss: 0.5814\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5726 - val_loss: 0.5770\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5675 - val_loss: 0.5726\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5624 - val_loss: 0.5681\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5574 - val_loss: 0.5639\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5522 - val_loss: 0.5598\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5471 - val_loss: 0.5550\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 0.5504\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5370 - val_loss: 0.5461\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 0.5421\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 0.5383\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 0.5342\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5187 - val_loss: 0.5306\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5145 - val_loss: 0.5274\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5105 - val_loss: 0.5237\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5067 - val_loss: 0.5205\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5172\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4992 - val_loss: 0.5143\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 0.5112\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4923 - val_loss: 0.5085\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4891 - val_loss: 0.5059\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4860 - val_loss: 0.5035\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4829 - val_loss: 0.5006\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4802 - val_loss: 0.4984\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 0.4964\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4940\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4721 - val_loss: 0.4926\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.4902\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4676 - val_loss: 0.4883\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4654 - val_loss: 0.4864\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.4846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.4831\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.4815\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.4797\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4781\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.4768\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4519 - val_loss: 0.4752\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4503 - val_loss: 0.4738\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4725\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4471 - val_loss: 0.4712\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4456 - val_loss: 0.4701\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4689\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4428 - val_loss: 0.4676\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.4665\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4402 - val_loss: 0.4652\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4389 - val_loss: 0.4641\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 0.4630\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.4622\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4353 - val_loss: 0.4609\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.4601\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4331 - val_loss: 0.4591\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4582\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 0.4576\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4299 - val_loss: 0.4564\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.4558\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4548\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4540\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4260 - val_loss: 0.4534\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.4526\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.4516\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4232 - val_loss: 0.4507\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4224 - val_loss: 0.4500\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4215 - val_loss: 0.4492\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.4483\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4476\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4471\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 0.4467\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4177 - val_loss: 0.4458\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.4452\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4161 - val_loss: 0.4448\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4024\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2251 - val_loss: 0.6893\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6346 - val_loss: 0.6042\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - val_loss: 0.5591\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5323 - val_loss: 0.5310\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5087 - val_loss: 0.5161\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4924 - val_loss: 0.4999\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4816 - val_loss: 0.4932\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4729 - val_loss: 0.4861\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4671 - val_loss: 0.4826\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4843\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4576 - val_loss: 0.4748\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4534 - val_loss: 0.4707\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4512 - val_loss: 0.4720\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.4652\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.4686\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.4615\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4600\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4592\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4617\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.4525\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4288 - val_loss: 0.4532\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.4556\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4485\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.4538\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.4458\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 0.4463\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4176 - val_loss: 0.4422\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4161 - val_loss: 0.4425\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.4379\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4388\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4380\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4103 - val_loss: 0.4341\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.4338\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4331\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 0.4326\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.4321\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4028 - val_loss: 0.4287\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4031 - val_loss: 0.4309\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4270\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4268\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.4243\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4228\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.4248\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4204\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.4195\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.4225\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.4177\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4218\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4153\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.4145\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.4168\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.4138\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.4151\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.4141\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4131\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.4098\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.4200\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.4194\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.4089\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.4091\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.4105\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.4051\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.4059\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.4170\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.4036\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.4063\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.4033\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.4023\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.4012\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.4015\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.4006\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.4061\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.4004\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3673 - val_loss: 0.3970\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.4057\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3986\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3965\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3962\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.3940\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3934\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3992\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3925\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3597 - val_loss: 0.4020\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3604 - val_loss: 0.3950\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.3924\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3584 - val_loss: 0.3911\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.3949\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3582 - val_loss: 0.3893\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3581 - val_loss: 0.3873\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3917\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3945\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3921\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 0.3967\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3552 - val_loss: 0.3871\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3914\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.3901\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.3857\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3877\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.3882\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3916\n",
      "121/121 [==============================] - 0s 860us/step - loss: 0.3527\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2722 - val_loss: 0.7968\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6874 - val_loss: 0.6506\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6297 - val_loss: 0.5533\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5211 - val_loss: 0.5343\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4897 - val_loss: 0.5130\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4771 - val_loss: 0.5021\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 0.4914\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4867\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4524 - val_loss: 0.4808\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.4809\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4410 - val_loss: 0.4711\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4672\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4341 - val_loss: 0.4653\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4292 - val_loss: 0.4619\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4752\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4563\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4550\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.4516\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.4528\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.4523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4452\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.4435\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.4422\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4056 - val_loss: 0.4451\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.4387\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4492\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4347\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.4349\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4347\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3952 - val_loss: 0.4335\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.4336\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.4276\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.4276\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.4268\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.4266\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.4292\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.4261\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3852 - val_loss: 0.4206\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.4213\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.4199\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.4211\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.4176\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.4203\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.4184\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.4151\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.4124\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.4137\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.4118\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.4097\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.4096\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.4323\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3693 - val_loss: 0.4107\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3728 - val_loss: 0.4082\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.4157\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 0.4058\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.6006\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.4080\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3673 - val_loss: 0.4071\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.4100\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.4083\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.4015\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3611 - val_loss: 0.4044\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3617 - val_loss: 0.4019\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.4221\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3615 - val_loss: 0.3994\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3583 - val_loss: 0.4019\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3986\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.4111\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3988\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3966\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.3945\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.4180\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.4005\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3978\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.3926\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3929\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.3925\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.4086\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3938\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3910\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.3910\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3506 - val_loss: 0.3902\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.4069\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.3918\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3882\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.3950\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.4080\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.3879\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.3852\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3888\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3859\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 0.3864\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3858\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3418 - val_loss: 0.3862\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3841\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3390 - val_loss: 0.3818\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.3837\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.3915\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.3821\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 0.3943\n",
      "121/121 [==============================] - 0s 948us/step - loss: 0.3657\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7762 - val_loss: 3.3899\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.5958 - val_loss: 0.9329\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.5343\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4948 - val_loss: 0.4944\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4617 - val_loss: 0.4755\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4428 - val_loss: 0.4642\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4300 - val_loss: 0.4554\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 0.4468\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4124 - val_loss: 0.4386\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4348\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.4276\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.4254\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.4235\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.4216\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.4222\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.4157\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.4195\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.4215\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.4164\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.4160\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.4119\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.4105\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.4140\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.4145\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.4071\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.4062\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.4103\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3716 - val_loss: 0.4040\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.4107\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.4154\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.4082\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.4052\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.4205\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.4058\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.4055\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.4004\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.4067\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.4010\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.4002\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.4033\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.4025\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.4028\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.4035\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.4011\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.4008\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.3986\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.4022\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.4007\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3929\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3987\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3981\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.4106\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.4058\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.3945\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.3918\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3996\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3934\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3885\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.3914\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3900\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.3885\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3904\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3897\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3877\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.3882\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3866\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.3855\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.3891\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3876\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3953\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3411 - val_loss: 0.3861\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.3899\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3837\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.3843\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3388 - val_loss: 0.3806\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3822\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3374 - val_loss: 0.3771\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3809\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.3799\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3343 - val_loss: 0.3808\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3343 - val_loss: 0.3795\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 0.3794\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 0.3816\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3788\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3776\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3797\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.3769\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3791\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 0.3785\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 0.3793\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.3772\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 0.3800\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3712\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3707\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.3710\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3739\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.3762\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3266 - val_loss: 0.3704\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3712\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.3717\n",
      "121/121 [==============================] - 0s 819us/step - loss: 0.3285\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6.9817 - val_loss: 7.6385\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1050 - val_loss: 5.4471\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8290 - val_loss: 4.0094\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9481 - val_loss: 3.0540\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3337 - val_loss: 2.4088\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8988 - val_loss: 1.9642\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5875 - val_loss: 1.6545\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3628 - val_loss: 1.4350\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1988 - val_loss: 1.2766\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0779 - val_loss: 1.1608\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9878 - val_loss: 1.0742\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9201 - val_loss: 1.0085\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8685 - val_loss: 0.9579\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8288 - val_loss: 0.9178\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7978 - val_loss: 0.8856\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7733 - val_loss: 0.8593\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7535 - val_loss: 0.8373\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7373 - val_loss: 0.8186\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7239 - val_loss: 0.8024\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7125 - val_loss: 0.7883\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7027 - val_loss: 0.7757\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6942 - val_loss: 0.7643\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6866 - val_loss: 0.7541\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6798 - val_loss: 0.7446\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6736 - val_loss: 0.7358\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6679 - val_loss: 0.7277\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6627 - val_loss: 0.7201\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6578 - val_loss: 0.7130\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6532 - val_loss: 0.7063\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6489 - val_loss: 0.7000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6449 - val_loss: 0.6941\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6410 - val_loss: 0.6885\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6373 - val_loss: 0.6830\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6338 - val_loss: 0.6780\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6305 - val_loss: 0.6733\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6273 - val_loss: 0.6687\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6242 - val_loss: 0.6643\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6213 - val_loss: 0.6602\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6184 - val_loss: 0.6563\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6157 - val_loss: 0.6526\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6131 - val_loss: 0.6490\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6456\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6082 - val_loss: 0.6423\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6058 - val_loss: 0.6391\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6036 - val_loss: 0.6360\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6014 - val_loss: 0.6332\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5993 - val_loss: 0.6304\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6279\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5953 - val_loss: 0.6254\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5934 - val_loss: 0.6229\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5916 - val_loss: 0.6206\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5898 - val_loss: 0.6184\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5881 - val_loss: 0.6163\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5864 - val_loss: 0.6142\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5848 - val_loss: 0.6123\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5832 - val_loss: 0.6104\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5817 - val_loss: 0.6086\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5803 - val_loss: 0.6067\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5788 - val_loss: 0.6050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5775 - val_loss: 0.6035\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5761 - val_loss: 0.6019\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5748 - val_loss: 0.6003\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5735 - val_loss: 0.5988\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5723 - val_loss: 0.5973\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5711 - val_loss: 0.5960\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5699 - val_loss: 0.5947\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5688 - val_loss: 0.5934\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5677 - val_loss: 0.5921\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5666 - val_loss: 0.5909\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5656 - val_loss: 0.5898\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5646 - val_loss: 0.5886\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5636 - val_loss: 0.5875\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5626 - val_loss: 0.5865\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5616 - val_loss: 0.5854\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5608 - val_loss: 0.5844\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5598 - val_loss: 0.5834\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5589 - val_loss: 0.5825\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5581 - val_loss: 0.5816\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5573 - val_loss: 0.5807\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5565 - val_loss: 0.5798\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5557 - val_loss: 0.5790\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5549 - val_loss: 0.5781\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5541 - val_loss: 0.5773\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5534 - val_loss: 0.5765\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5527 - val_loss: 0.5757\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5520 - val_loss: 0.5751\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5513 - val_loss: 0.5743\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5506 - val_loss: 0.5737\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5500 - val_loss: 0.5729\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5493 - val_loss: 0.5723\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5487 - val_loss: 0.5716\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5481 - val_loss: 0.5710\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5475 - val_loss: 0.5703\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5469 - val_loss: 0.5697\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5464 - val_loss: 0.5691\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5458 - val_loss: 0.5685\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5452 - val_loss: 0.5679\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5447 - val_loss: 0.5674\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5442 - val_loss: 0.5669\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5437 - val_loss: 0.5664\n",
      "121/121 [==============================] - 0s 840us/step - loss: 0.5404\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7.8939 - val_loss: 6.8271\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.8073 - val_loss: 5.0843\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3651 - val_loss: 3.8669\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3507 - val_loss: 3.0030\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6287 - val_loss: 2.3829\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1084 - val_loss: 1.9338\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7300 - val_loss: 1.6054\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4520 - val_loss: 1.3633\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2463 - val_loss: 1.1844\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0933 - val_loss: 1.0509\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9783 - val_loss: 0.9509\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8916 - val_loss: 0.8758\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8258 - val_loss: 0.8188\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7754 - val_loss: 0.7754\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7367 - val_loss: 0.7421\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7066 - val_loss: 0.7164\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6831 - val_loss: 0.6963\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6645 - val_loss: 0.6805\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6497 - val_loss: 0.6679\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6377 - val_loss: 0.6579\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6279 - val_loss: 0.6497\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6199 - val_loss: 0.6428\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6131 - val_loss: 0.6371\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6073 - val_loss: 0.6323\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6023 - val_loss: 0.6280\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6243\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5941 - val_loss: 0.6209\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5907 - val_loss: 0.6179\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5875 - val_loss: 0.6152\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5846 - val_loss: 0.6127\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5820 - val_loss: 0.6103\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5795 - val_loss: 0.6081\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5771 - val_loss: 0.6059\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - val_loss: 0.6039\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - val_loss: 0.6021\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5708 - val_loss: 0.6003\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5689 - val_loss: 0.5985\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5671 - val_loss: 0.5968\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5653 - val_loss: 0.5952\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5636 - val_loss: 0.5937\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - val_loss: 0.5923\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5604 - val_loss: 0.5908\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5589 - val_loss: 0.5894\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5574 - val_loss: 0.5880\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5560 - val_loss: 0.5866\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5546 - val_loss: 0.5853\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5533 - val_loss: 0.5841\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5519 - val_loss: 0.5829\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5507 - val_loss: 0.5817\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5495 - val_loss: 0.5805\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5483 - val_loss: 0.5795\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5471 - val_loss: 0.5784\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5460 - val_loss: 0.5774\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5449 - val_loss: 0.5763\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5438 - val_loss: 0.5754\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5428 - val_loss: 0.5744\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5418 - val_loss: 0.5735\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5408 - val_loss: 0.5726\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5398 - val_loss: 0.5717\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - val_loss: 0.5709\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5380 - val_loss: 0.5700\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5371 - val_loss: 0.5692\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5363 - val_loss: 0.5685\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5354 - val_loss: 0.5676\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5346 - val_loss: 0.5669\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5339 - val_loss: 0.5662\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5331 - val_loss: 0.5654\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5323 - val_loss: 0.5647\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5641\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5309 - val_loss: 0.5634\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5302 - val_loss: 0.5627\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.5622\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5289 - val_loss: 0.5616\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5283 - val_loss: 0.5610\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5604\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5271 - val_loss: 0.5599\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5265 - val_loss: 0.5593\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 0.5588\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5254 - val_loss: 0.5584\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5249 - val_loss: 0.5580\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 0.5575\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 0.5570\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 0.5565\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5229 - val_loss: 0.5561\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5224 - val_loss: 0.5556\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5219 - val_loss: 0.5553\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5215 - val_loss: 0.5549\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5211 - val_loss: 0.5545\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.5541\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5202 - val_loss: 0.5538\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5198 - val_loss: 0.5534\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.5530\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5525\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5522\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5519\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5180 - val_loss: 0.5517\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.5514\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5174 - val_loss: 0.5511\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5170 - val_loss: 0.5508\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5167 - val_loss: 0.5505\n",
      "121/121 [==============================] - 0s 829us/step - loss: 0.5566\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.9390 - val_loss: 5.2205\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4272 - val_loss: 3.9197\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3732 - val_loss: 3.0097\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6292 - val_loss: 2.3680\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0992 - val_loss: 1.9103\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7183 - val_loss: 1.5814\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4428 - val_loss: 1.3435\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2416 - val_loss: 1.1696\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0938 - val_loss: 1.0424\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9849 - val_loss: 0.9487\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9041 - val_loss: 0.8793\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8436 - val_loss: 0.8271\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7982 - val_loss: 0.7880\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7637 - val_loss: 0.7584\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7373 - val_loss: 0.7358\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7168 - val_loss: 0.7182\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7009 - val_loss: 0.7043\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6882 - val_loss: 0.6932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6780 - val_loss: 0.6843\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6695 - val_loss: 0.6769\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6625 - val_loss: 0.6708\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6566 - val_loss: 0.6655\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6514 - val_loss: 0.6608\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6468 - val_loss: 0.6568\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6427 - val_loss: 0.6531\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6390 - val_loss: 0.6496\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6355 - val_loss: 0.6464\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6323 - val_loss: 0.6435\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6293 - val_loss: 0.6406\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6265 - val_loss: 0.6380\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6237 - val_loss: 0.6354\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6211 - val_loss: 0.6329\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6186 - val_loss: 0.6304\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6162 - val_loss: 0.6281\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6139 - val_loss: 0.6259\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.6238\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6095 - val_loss: 0.6218\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6074 - val_loss: 0.6198\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6053 - val_loss: 0.6178\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6033 - val_loss: 0.6159\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6014 - val_loss: 0.6141\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6123\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6104\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6087\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5941 - val_loss: 0.6071\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5924 - val_loss: 0.6054\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5908 - val_loss: 0.6039\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5892 - val_loss: 0.6023\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5876 - val_loss: 0.6009\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5861 - val_loss: 0.5994\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5846 - val_loss: 0.5980\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5832 - val_loss: 0.5966\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5817 - val_loss: 0.5953\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5804 - val_loss: 0.5939\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5790 - val_loss: 0.5927\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5777 - val_loss: 0.5914\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5765 - val_loss: 0.5902\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.5890\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5740 - val_loss: 0.5879\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - val_loss: 0.5868\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - val_loss: 0.5857\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5706 - val_loss: 0.5847\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - val_loss: 0.5837\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5684 - val_loss: 0.5826\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5674 - val_loss: 0.5816\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5664 - val_loss: 0.5806\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5654 - val_loss: 0.5797\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5644 - val_loss: 0.5788\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5635 - val_loss: 0.5778\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5626 - val_loss: 0.5769\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5617 - val_loss: 0.5761\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5608 - val_loss: 0.5753\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5600 - val_loss: 0.5745\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5592 - val_loss: 0.5738\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5584 - val_loss: 0.5730\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5576 - val_loss: 0.5723\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5568 - val_loss: 0.5716\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5561 - val_loss: 0.5709\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5553 - val_loss: 0.5702\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5546 - val_loss: 0.5696\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5540 - val_loss: 0.5689\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5533 - val_loss: 0.5683\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5526 - val_loss: 0.5676\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5520 - val_loss: 0.5670\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5514 - val_loss: 0.5664\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5508 - val_loss: 0.5658\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5502 - val_loss: 0.5652\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5496 - val_loss: 0.5647\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5490 - val_loss: 0.5642\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5485 - val_loss: 0.5636\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5479 - val_loss: 0.5631\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5474 - val_loss: 0.5627\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5469 - val_loss: 0.5621\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5464 - val_loss: 0.5616\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5459 - val_loss: 0.5612\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5454 - val_loss: 0.5609\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5449 - val_loss: 0.5604\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5445 - val_loss: 0.5600\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5440 - val_loss: 0.5596\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5436 - val_loss: 0.5592\n",
      "121/121 [==============================] - 0s 872us/step - loss: 0.5160\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2701 - val_loss: 0.7269\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6456 - val_loss: 0.6159\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5701 - val_loss: 0.5619\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.5266\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4941 - val_loss: 0.5047\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.4854\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4742\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4455 - val_loss: 0.4633\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4561\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4294 - val_loss: 0.4582\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4431\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4376\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.4395\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.4290\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4052 - val_loss: 0.4358\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4030 - val_loss: 0.4225\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3987 - val_loss: 0.4221\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3954 - val_loss: 0.4201\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3925 - val_loss: 0.4196\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4128\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.4109\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.4151\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.4068\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.4154\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.4024\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.4037\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.4019\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3987\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.3924\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.3929\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.3925\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 0.3895\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3619 - val_loss: 0.3868\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3603 - val_loss: 0.3877\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3874\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.3861\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3545 - val_loss: 0.3839\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3838\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3520 - val_loss: 0.3801\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3816\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3768\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.3757\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3461 - val_loss: 0.3767\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3733\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.3744\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 0.3741\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3418 - val_loss: 0.3715\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.3757\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3391 - val_loss: 0.3696\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3377 - val_loss: 0.3714\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3853\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.3683\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.3692\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3343 - val_loss: 0.3690\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.3675\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.3650\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3306 - val_loss: 0.3757\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.3703\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3295 - val_loss: 0.3646\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.3631\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3267 - val_loss: 0.3663\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3264 - val_loss: 0.3619\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3253 - val_loss: 0.3620\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3249 - val_loss: 0.3830\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3269 - val_loss: 0.3586\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.3630\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3235 - val_loss: 0.3592\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3225 - val_loss: 0.3628\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.3573\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.3576\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3188 - val_loss: 0.3573\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3176 - val_loss: 0.3640\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3615\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3172 - val_loss: 0.3573\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3162 - val_loss: 0.3590\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3157 - val_loss: 0.3595\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 0.3548\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.3558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.3541\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3133 - val_loss: 0.3526\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3518\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3115 - val_loss: 0.3502\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3560\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3539\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3498\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3092 - val_loss: 0.3505\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3511\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.3500\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3079 - val_loss: 0.3477\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3063 - val_loss: 0.3503\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3547\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3068 - val_loss: 0.3489\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3056 - val_loss: 0.3532\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 0.3477\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3040 - val_loss: 0.3491\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3465\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3040 - val_loss: 0.3446\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.3454\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.3468\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3527\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3215\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2430 - val_loss: 0.7883\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7027 - val_loss: 0.6517\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6175 - val_loss: 0.5730\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5311 - val_loss: 0.5521\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4993 - val_loss: 0.5221\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4806 - val_loss: 0.5057\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4669 - val_loss: 0.4921\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4833\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.4743\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 0.4670\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 0.4584\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4210 - val_loss: 0.4525\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4152 - val_loss: 0.4485\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4100 - val_loss: 0.4450\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4051 - val_loss: 0.4501\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4017 - val_loss: 0.4364\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.4346\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4294\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3904 - val_loss: 0.4274\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3883 - val_loss: 0.4268\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.4222\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.4207\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.4214\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.4194\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.4144\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3740 - val_loss: 0.4240\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.4101\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.4096\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.4087\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.4082\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3646 - val_loss: 0.4044\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3641 - val_loss: 0.4020\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3619 - val_loss: 0.4016\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3608 - val_loss: 0.4012\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3587 - val_loss: 0.4014\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.3976\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.4004\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.3958\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3949\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3511 - val_loss: 0.3956\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3493 - val_loss: 0.3948\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3493 - val_loss: 0.3921\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3476 - val_loss: 0.3929\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 0.3902\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3454 - val_loss: 0.3903\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.3878\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3433 - val_loss: 0.3893\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3416 - val_loss: 0.3876\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3396 - val_loss: 0.3857\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3394 - val_loss: 0.3855\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3395 - val_loss: 0.3930\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.3838\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.3826\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.3846\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.3815\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3322 - val_loss: 0.3815\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.3813\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.3850\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3783\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.3768\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.3779\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.3785\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3753\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.3844\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3277 - val_loss: 0.3730\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3738\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3234 - val_loss: 0.3721\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.3734\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3235 - val_loss: 0.3728\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3701\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3204 - val_loss: 0.3681\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3195 - val_loss: 0.3708\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3194 - val_loss: 0.3685\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3185 - val_loss: 0.3677\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3174 - val_loss: 0.3686\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3665\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.3672\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.3660\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.3637\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3175 - val_loss: 0.3659\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3143 - val_loss: 0.3640\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.3627\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3109 - val_loss: 0.3639\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3101 - val_loss: 0.3637\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3101 - val_loss: 0.3616\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3630\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3613\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.3589\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3066 - val_loss: 0.3570\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.3592\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.3609\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3057 - val_loss: 0.3629\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3036 - val_loss: 0.3670\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3046 - val_loss: 0.3593\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3045 - val_loss: 0.3556\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3028 - val_loss: 0.3566\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3060 - val_loss: 0.3551\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3079 - val_loss: 0.3575\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3016 - val_loss: 0.3550\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3594\n",
      "121/121 [==============================] - 0s 966us/step - loss: 0.3332\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1477 - val_loss: 0.7964\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8341 - val_loss: 0.8288\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7072 - val_loss: 0.6062\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5727 - val_loss: 0.5572\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5313 - val_loss: 0.5243\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5031 - val_loss: 0.5049\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.4920\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4687 - val_loss: 0.4785\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.4679\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4469 - val_loss: 0.4611\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4407 - val_loss: 0.4543\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4342 - val_loss: 0.4507\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4273 - val_loss: 0.4438\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4225 - val_loss: 0.4417\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4172 - val_loss: 0.4408\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4310\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.4325\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.4292\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4024 - val_loss: 0.4244\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.4238\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.4230\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4194\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4163\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3883 - val_loss: 0.4192\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.4130\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.4089\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.4116\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3794 - val_loss: 0.4046\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 0.4066\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.4049\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.4030\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4031\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.4046\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3674 - val_loss: 0.4001\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3660 - val_loss: 0.3970\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3633 - val_loss: 0.3939\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3617 - val_loss: 0.4013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.3908\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3581 - val_loss: 0.3925\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3574 - val_loss: 0.3881\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.3905\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3540 - val_loss: 0.3885\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3904\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.3877\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.3826\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3826\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3467 - val_loss: 0.3843\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 0.3794\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3437 - val_loss: 0.3773\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.3763\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.3754\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3402 - val_loss: 0.3792\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3385 - val_loss: 0.3746\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3373 - val_loss: 0.3723\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3361 - val_loss: 0.3726\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.3750\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3334 - val_loss: 0.3739\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.3682\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3321 - val_loss: 0.3683\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3309 - val_loss: 0.3682\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.3673\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3284 - val_loss: 0.3687\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.3693\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3273 - val_loss: 0.3645\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3259 - val_loss: 0.3674\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3260 - val_loss: 0.3625\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3245 - val_loss: 0.3623\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3242 - val_loss: 0.3657\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3227 - val_loss: 0.3629\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3221 - val_loss: 0.3607\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3213 - val_loss: 0.3586\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3208 - val_loss: 0.3622\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3200 - val_loss: 0.3587\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3186 - val_loss: 0.3562\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3187 - val_loss: 0.3595\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3178 - val_loss: 0.3559\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3167 - val_loss: 0.3581\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3157 - val_loss: 0.3607\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3153 - val_loss: 0.3541\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3144 - val_loss: 0.3568\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3562\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3132 - val_loss: 0.3600\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.3593\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3130 - val_loss: 0.3549\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3123 - val_loss: 0.3540\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.3580\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3101 - val_loss: 0.3532\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3087 - val_loss: 0.3521\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3087 - val_loss: 0.3598\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.3545\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3076 - val_loss: 0.3523\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3071 - val_loss: 0.3569\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3064 - val_loss: 0.3555\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3067 - val_loss: 0.3484\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3054 - val_loss: 0.3468\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3043 - val_loss: 0.3491\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3034 - val_loss: 0.3510\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3037 - val_loss: 0.3485\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3029 - val_loss: 0.3474\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3028 - val_loss: 0.3511\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3205\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9753 - val_loss: 0.7160\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6617 - val_loss: 0.5958\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5478 - val_loss: 0.5212\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4845 - val_loss: 0.4924\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4579 - val_loss: 0.4734\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4411 - val_loss: 0.4615\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4307 - val_loss: 0.4509\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4215 - val_loss: 0.4440\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4144 - val_loss: 0.4369\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4097 - val_loss: 0.4332\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4036 - val_loss: 0.4294\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3990 - val_loss: 0.4255\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3948 - val_loss: 0.4246\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.4194\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3868 - val_loss: 0.4246\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3840 - val_loss: 0.4106\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3799 - val_loss: 0.4119\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3766 - val_loss: 0.4058\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3736 - val_loss: 0.4021\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3706 - val_loss: 0.4023\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3680 - val_loss: 0.3973\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3648 - val_loss: 0.3985\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3613 - val_loss: 0.3964\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3597 - val_loss: 0.3925\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3570 - val_loss: 0.3905\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3549 - val_loss: 0.3899\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.3925\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3519 - val_loss: 0.3869\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3503 - val_loss: 0.3839\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3480 - val_loss: 0.3833\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3458 - val_loss: 0.3889\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3816\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3418 - val_loss: 0.3781\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3397 - val_loss: 0.3770\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3386 - val_loss: 0.3775\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3391 - val_loss: 0.3734\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3348 - val_loss: 0.3786\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3358 - val_loss: 0.3702\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3323 - val_loss: 0.3786\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3315 - val_loss: 0.3751\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3300 - val_loss: 0.3720\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3293 - val_loss: 0.3713\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3273 - val_loss: 0.3696\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3273 - val_loss: 0.3644\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3258 - val_loss: 0.3651\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3253 - val_loss: 0.3662\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3237 - val_loss: 0.3621\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3230 - val_loss: 0.3735\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3224 - val_loss: 0.3728\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3224 - val_loss: 0.3603\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3204 - val_loss: 0.3575\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3186 - val_loss: 0.3645\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3186 - val_loss: 0.3565\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 0.3553\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3162 - val_loss: 0.3629\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3204 - val_loss: 0.3571\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3144 - val_loss: 0.3594\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3144 - val_loss: 0.3539\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3124 - val_loss: 0.3547\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3145 - val_loss: 0.3514\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3129 - val_loss: 0.3508\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3112 - val_loss: 0.3607\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3112 - val_loss: 0.3498\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3090 - val_loss: 0.3521\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3088 - val_loss: 0.3494\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3063 - val_loss: 0.3466\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3072 - val_loss: 0.3470\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3058 - val_loss: 0.3515\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3048 - val_loss: 0.3624\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3042 - val_loss: 0.3560\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3036 - val_loss: 0.3498\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3042 - val_loss: 0.3464\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3033 - val_loss: 0.3438\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3041 - val_loss: 0.3495\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3009 - val_loss: 0.3486\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3012 - val_loss: 0.3416\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3012 - val_loss: 0.3574\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3009 - val_loss: 0.3434\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3003 - val_loss: 0.3519\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2988 - val_loss: 0.3400\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2985 - val_loss: 0.3409\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3000 - val_loss: 0.3468\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2987 - val_loss: 0.3439\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2989 - val_loss: 0.3397\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2961 - val_loss: 0.3547\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2972 - val_loss: 0.3451\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2946 - val_loss: 0.3372\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2958 - val_loss: 0.3439\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2956 - val_loss: 0.3387\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2954 - val_loss: 0.3415\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2954 - val_loss: 0.3438\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2944 - val_loss: 0.3355\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2930 - val_loss: 0.3370\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2914 - val_loss: 0.3325\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2921 - val_loss: 0.3349\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2919 - val_loss: 0.3507\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2948 - val_loss: 0.3326\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2951 - val_loss: 0.3298\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2899 - val_loss: 0.3330\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2901 - val_loss: 0.3303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B9370FE310>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001B9370FED60>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    'n_hidden' : [0, 1, 2, 3],\n",
    "    'n_neurons' : np.arange(1, 100),\n",
    "    'learning_rate' : reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_serach_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_serach_cv.fit(X_train, y_train, epochs=100, validation_data = (X_valid, y_valid), \n",
    "                  callbacks = [keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "77a5a389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_serach_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eff2bc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3250718414783478"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_serach_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f63a5163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x1b933462cd0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_serach_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bcdff88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.31140896677970886"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_serach_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "44c96aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1b93e558eb0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_serach_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4fcaba00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31140896677970886"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca4483",
   "metadata": {},
   "source": [
    "# 퍼셉트론의 하이퍼파라미터 선택 요령"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065378f",
   "metadata": {},
   "source": [
    "## 10.3.1 은닉층 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b0ea7",
   "metadata": {},
   "source": [
    "이론적으로는 hidden layer가 하나인 MLP더라도 뉴런 개수가 충분하면 아주 복잡한 함수도 모델링 가능. 하지만 복잡한 문제에선 심층 신경망이 얕은 신경망보다 파라미터 효율성이 좋다.(분업의 이유 등)\n",
    "\n",
    "심층신경망이 좋은 솔루션으로 수렴하도록 도와줄 뿐 아니라 새로운 데이터에 일반화 하는 능력도 좋다. 전이학습 등의 이유 때문에\n",
    "\n",
    "복잡한 문제라면 훈련셋에 과대적합이 생길 때까지 점진적으로 hidden layer의 수를 늘릴 수 있으나 훈련데이터가 아주 많이 필요하기 때문에 한계 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf87ece",
   "metadata": {},
   "source": [
    "## 10.3.2 뉴런 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04139cb",
   "metadata": {},
   "source": [
    "입력층과 출력층의 뉴런 개수는 해당 작업에 필요한 입력과 출력의 형태에 따라 결정. MNIST의 경우 28 x 28 = 784개의 입력뉴런과 10개의 출력 뉴런이 필요\n",
    "\n",
    "은닉층은 일반적으로 각 층의 뉴런을 점점 줄여가며 깔때기처럼 구성\n",
    "\n",
    "하지만 요즘엔 모든 은닉층에 같은 크기를 사용해도 동일하거나 더 나은 성능을 내며, 같은 크기를 사용하면 튜닝할 하이퍼파라미터가 층마다 한 개씩이 아니라 전체를 통틀어 하나가 된다.\n",
    "\n",
    "층의 개수와 마찬가지고 과대적합이 시작되기 전까지 점진적으로 뉴런 수를 늘릴 수 있음. 하지만 실전에서는 필요 이상의 층과 뉴런을 가진 모델을 선택하고, 조기종료나 규제기법 등을 사용하는 게 일반적\n",
    "\n",
    "-> 모델에서 문제를 일으키는 병목층을 피할 수 있으며, 너무 적은 뉴런으로 인해 초래되는 불충분한 표현능력 걱정 X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522962a2",
   "metadata": {},
   "source": [
    "## 10.3.3 학습률, 배치크기, 그리고 다른 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82648645",
   "metadata": {},
   "source": [
    "### 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f7891",
   "metadata": {},
   "source": [
    "일반적으로는 매우 낮은 학습률에서 시작해서 매우 큰 학습률까지 수백번 반복하여 모델을 훈련하는 방법이 좋다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286a226",
   "metadata": {},
   "source": [
    "### 옵티마이저"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f125f0",
   "metadata": {},
   "source": [
    "고전적인 평범한 미니배치보다 더 좋은 것을 선택하는 것이 중요. 11장에서 다룸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963edbe9",
   "metadata": {},
   "source": [
    "### 배치 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c99f11",
   "metadata": {},
   "source": [
    "너무 큰 배치를 이용하면 훈련 초기에 종종 불안정하게 훈련된다. 보통 큰 배치크기를 시도해보고 만족스럽지 않을 경우 작은 배치크기를 사용하는 게 좋을 것이라고 저자는 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab04283",
   "metadata": {},
   "source": [
    "### 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a35da",
   "metadata": {},
   "source": [
    "일반적으로는 ReLU가 모든 Hidden Layer에 좋은 기본값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909a5ab",
   "metadata": {},
   "source": [
    "### 반복 횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f26fe",
   "metadata": {},
   "source": [
    "대부분의 경우 반복횟수를 튜닝하기 보단 조기종료를 사용한다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
